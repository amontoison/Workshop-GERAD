{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWzKSgrFLvDi"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amontoison/Workshop-GERAD/blob/main/gpu_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJSpcY8KLvDn"
      },
      "source": [
        "# Parallel computing and GPU programming with Julia\n",
        "## Part III: GPU programming\n",
        "Alexis Montoison"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Pkg\n",
        "Pkg.activate(\"colab5\")\n",
        "Pkg.add([\"BenchmarkTools\", \"CUDA\"])"
      ],
      "metadata": {
        "id": "r1Xncjz-ZjUl",
        "outputId": "995a016c-36ee-480b-c786-88be03b09066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `/content/colab5`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ─ v1.6.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/content/colab5/Project.toml`\n",
            "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
            "  \u001b[90m[052768ef] \u001b[39m\u001b[92m+ CUDA v5.8.3\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/content/colab5/Manifest.toml`\n",
            "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
            "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.3.0\u001b[39m\n",
            "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.2\u001b[39m\n",
            "  \u001b[90m[ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.5.1\u001b[39m\n",
            "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
            "  \u001b[90m[fa961155] \u001b[39m\u001b[92m+ CEnum v0.5.0\u001b[39m\n",
            "  \u001b[90m[052768ef] \u001b[39m\u001b[92m+ CUDA v5.8.3\u001b[39m\n",
            "  \u001b[90m[1af6417a] \u001b[39m\u001b[92m+ CUDA_Runtime_Discovery v1.0.0\u001b[39m\n",
            "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.1\u001b[39m\n",
            "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.1\u001b[39m\n",
            "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.18.0\u001b[39m\n",
            "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
            "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
            "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.8.0\u001b[39m\n",
            "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.19.1\u001b[39m\n",
            "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
            "  \u001b[90m[e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.10\u001b[39m\n",
            "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
            "  \u001b[90m[0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v11.2.5\u001b[39m\n",
            "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
            "  \u001b[90m[61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v1.6.1\u001b[39m\n",
            "  \u001b[90m[096a3bc2] \u001b[39m\u001b[92m+ GPUToolbox v0.3.0\u001b[39m\n",
            "  \u001b[90m[076d061b] \u001b[39m\u001b[92m+ HashArrayMappedTries v0.2.0\u001b[39m\n",
            "  \u001b[90m[842dd82b] \u001b[39m\u001b[92m+ InlineStrings v1.4.5\u001b[39m\n",
            "  \u001b[90m[41ab1584] \u001b[39m\u001b[92m+ InvertedIndices v1.3.1\u001b[39m\n",
            "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
            "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.1\u001b[39m\n",
            "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
            "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.38\u001b[39m\n",
            "  \u001b[90m[929cbde3] \u001b[39m\u001b[92m+ LLVM v9.4.2\u001b[39m\n",
            "  \u001b[90m[8b046642] \u001b[39m\u001b[92m+ LLVMLoopInfo v1.0.0\u001b[39m\n",
            "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
            "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.16\u001b[39m\n",
            "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
            "  \u001b[90m[5da4648a] \u001b[39m\u001b[92m+ NVTX v1.0.1\u001b[39m\n",
            "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.1\u001b[39m\n",
            "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.3\u001b[39m\n",
            "  \u001b[90m[2dfb63ee] \u001b[39m\u001b[92m+ PooledArrays v1.4.3\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
            "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.5.0\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
            "  \u001b[90m[74087812] \u001b[39m\u001b[92m+ Random123 v1.7.1\u001b[39m\n",
            "  \u001b[90m[e6cf234a] \u001b[39m\u001b[92m+ RandomNumbers v1.6.0\u001b[39m\n",
            "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
            "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
            "  \u001b[90m[7e506255] \u001b[39m\u001b[92m+ ScopedValues v1.5.0\u001b[39m\n",
            "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.3.0\u001b[39m\n",
            "  \u001b[90m[91c51154] \u001b[39m\u001b[92m+ SentinelArrays v1.4.8\u001b[39m\n",
            "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.2\u001b[39m\n",
            "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.15\u001b[39m\n",
            "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.3\u001b[39m\n",
            "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
            "  \u001b[90m[892a3eda] \u001b[39m\u001b[92m+ StringManipulation v0.4.1\u001b[39m\n",
            "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
            "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.1\u001b[39m\n",
            "  \u001b[90m[e689c965] \u001b[39m\u001b[92m+ Tracy v0.1.6\u001b[39m\n",
            "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
            "  \u001b[90m[d1e2174e] \u001b[39m\u001b[92m+ CUDA_Compiler_jll v0.2.1+0\u001b[39m\n",
            "  \u001b[90m[4ee394cb] \u001b[39m\u001b[92m+ CUDA_Driver_jll v13.0.1+0\u001b[39m\n",
            "  \u001b[90m[76a88914] \u001b[39m\u001b[92m+ CUDA_Runtime_jll v0.19.1+0\u001b[39m\n",
            "  \u001b[90m[9c1d0b0a] \u001b[39m\u001b[92m+ JuliaNVTXCallbacks_jll v0.2.1+0\u001b[39m\n",
            "  \u001b[90m[dad2f222] \u001b[39m\u001b[92m+ LLVMExtra_jll v0.0.37+2\u001b[39m\n",
            "  \u001b[90m[ad6e5548] \u001b[39m\u001b[92m+ LibTracyClient_jll v0.9.1+6\u001b[39m\n",
            "  \u001b[90m[e98f9f5b] \u001b[39m\u001b[92m+ NVTX_jll v3.2.2+0\u001b[39m\n",
            "  \u001b[90m[1e29f10c] \u001b[39m\u001b[92m+ demumble_jll v1.3.0+0\u001b[39m\n",
            "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
            "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
            "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
            "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
            "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
            "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
            "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
            "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
            "  \u001b[90m[4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts v1.11.0\u001b[39m\n",
            "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
            "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
            "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
            "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.11.0\u001b[39m\n",
            "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
            "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
            "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
            "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
            "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.11.0\u001b[39m\n",
            "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
            "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile v1.11.0\u001b[39m\n",
            "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
            "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
            "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
            "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.11.0\u001b[39m\n",
            "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
            "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
            "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
            "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
            "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.1.1+0\u001b[39m\n",
            "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.6.0+0\u001b[39m\n",
            "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.7.2+0\u001b[39m\n",
            "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
            "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.6+0\u001b[39m\n",
            "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2023.12.12\u001b[39m\n",
            "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.27+1\u001b[39m\n",
            "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.7.0+0\u001b[39m\n",
            "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+1\u001b[39m\n",
            "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.11.0+0\u001b[39m\n",
            "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.59.0+0\u001b[39m\n",
            "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+2\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   1670.2 ms\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
            "  1 dependency successfully precompiled in 5 seconds. 107 already precompiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PmTBFiIfLvDn"
      },
      "outputs": [],
      "source": [
        "using BenchmarkTools\n",
        "using CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCUsSCCLLvDq"
      },
      "source": [
        "Julia has first-class support for GPU programming through the following packages:\n",
        "\n",
        "#### Core\n",
        "- [GPUCompiler.jl](https://github.com/JuliaGPU/GPUCompiler.jl): Takes native Julia code and compiles it directly to GPUs\n",
        "- [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl): High-level array based common functionality\n",
        "- [KernelAbstractions.jl](https://github.com/JuliaGPU/KernelAbstractions.jl): Vendor-agnostic kernel programming language\n",
        "- [Adapt.jl](https://github.com/JuliaGPU/Adapt.jl): Translate complex structs across the host-device boundary\n",
        "\n",
        "#### Vendor specific\n",
        "\n",
        "- [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) for NVIDIA GPUs\n",
        "- [AMDGPU.jl](https://github.com/JuliaGPU/AMDGPU.jl) for AMD GPUs\n",
        "- [oneAPI.jl](https://github.com/JuliaGPU/oneAPI.jl) for Intel GPUs\n",
        "- [Metal.jl](https://github.com/JuliaGPU/Metal.jl) for Apple M-series GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK50CkoNLvDr"
      },
      "source": [
        "CUDA.jl is the most mature and we will use it for the workshop.\n",
        "AMDGPU.jl is somewhat behind but still ready for general use, while oneAPI.jl and Metal.jl are functional but might contain bugs, miss some features and provide suboptimal performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVE8IUEiLvDs"
      },
      "source": [
        "What is the difference between a CPU and a GPU?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK0bW6vLLvDs"
      },
      "source": [
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/cpu_vs_gpu.png?raw=1' width='700'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXoSWpgYLvDt"
      },
      "source": [
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/meme_gpu.jpg?raw=1' width='300'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbtsaYHULvDu"
      },
      "source": [
        "Some key aspects of GPUs that need to be kept in mind:\n",
        "- The large number of compute elements on a GPU (in the thousands) can enable extreme scaling for data parallel tasks.\n",
        "- GPUs have their own memory. This means that data needs to be transfered to and from the GPU during the execution of a program.\n",
        "- Cores in a GPU are arranged into a particular structure. At the highest level they are divided into “streaming multiprocessors” (SMs). Some of these details are important when writing own GPU kernels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G42_WZLQLvDv"
      },
      "source": [
        "<img src=\"https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/gpu.png?raw=1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQR6nLApLvDw"
      },
      "source": [
        "<img src=\"https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/gpu_topology.svg?raw=1\" width=500px>\n",
        "\n",
        "* **host**: CPU + system memory (host memory)\n",
        "* **device**: GPU with its memory (device memory)\n",
        "* **SM**: Streaming Multiprocessor\n",
        "\n",
        "Communication:\n",
        "* Host-device bandwidth: **31.5 GB/s**\n",
        "* GPU global memory bandwidth: **1555 GB/s**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD5oZIcLLvDx"
      },
      "source": [
        "GPU programming with Julia can be as simple as using a different array type instead of regular `Base.Array` arrays:\n",
        "- `CuArray` from CUDA.jl for NVIDIA GPUs\n",
        "- `ROCArray` from AMDGPU.jl for AMD GPUs\n",
        "- `oneArray` from oneAPI.jl for Intel GPUs\n",
        "- `MtlArray` from Metal.jl for Apple GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E0BSZ7cLvDy"
      },
      "source": [
        "These array types are subtypes of `GPUArrays` from [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) and closely resemble `Base.Array` which enables us to write generic code which works on both CPU and GPU arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KGAgnluBLvDz",
        "outputId": "2de0143b-c8e2-4e3b-c82f-7d3544a8b50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4-element CuArray{Int64, 1, CUDA.DeviceMemory}:\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    A_d = CuArray([1,2,3,4])\n",
        "    A_d .+= 1\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX9LIbShLvD0"
      },
      "source": [
        "We can do the same operation with other subtypes of `GPUArrays`:\n",
        "```julia\n",
        "if AMDGPU.functional()\n",
        "    A_d = ROCArray([1,2,3,4])\n",
        "    A_d .+= 1\n",
        "end\n",
        "\n",
        "if oneAPI.functional()\n",
        "    A_d = oneArray([1,2,3,4])\n",
        "    A_d .+= 1\n",
        "end\n",
        "\n",
        "A_d = MtlArray([1,2,3,4])\n",
        "A_d .+= 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Q3S1mVLvD0"
      },
      "source": [
        "Moving an array back from the GPU to the CPU is simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PpxkY3XaLvD0",
        "outputId": "2c1580e5-f049-4885-d8d1-8421da34bc8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4-element Vector{Int64}:\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    A = Array(A_d)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60o83xldLvD1"
      },
      "source": [
        " <img src=\"https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/cpu_gpu_transfer.svg?raw=1\" width=180px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_RqyQ3cLvD2"
      },
      "source": [
        "However, the overhead of copying data to the GPU makes such simple calculations very slow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emIeDtvvLvD2"
      },
      "source": [
        "Let’s have a look at a more realistic example: matrix multiplication.\n",
        "We create two random arrays, one on the CPU and one on the GPU, and compare the performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bLZu37kpLvD3",
        "outputId": "8898f440-08d6-4ec7-f589-c6af4c2639c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1.986 s (3 allocations: 128.00 MiB)\n",
            "  2.879376 seconds (4.69 M CPU allocations: 241.683 MiB) (3 GPU allocations: 128.000 MiB, 0.01% memmgmt time)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096×4096 CuArray{Float64, 2, CUDA.DeviceMemory}:\n",
              " 1026.99  1015.3   1025.14  1031.25  …  1016.87  1008.68  1034.22  1011.5\n",
              " 1047.13  1026.29  1044.63  1049.7      1032.05  1042.32  1055.84  1039.99\n",
              " 1040.51  1024.55  1037.85  1024.51     1035.03  1028.18  1048.08  1038.94\n",
              " 1034.67  1013.85  1028.39  1032.16     1022.21  1033.61  1037.04  1036.53\n",
              " 1044.02  1025.37  1028.57  1034.6      1015.15  1036.7   1052.18  1031.16\n",
              " 1024.72  1017.55  1028.31  1032.17  …  1016.58  1021.62  1029.85  1027.92\n",
              " 1028.99  1020.21  1020.69  1017.87     1019.39  1016.73  1023.25  1025.08\n",
              " 1041.94  1024.67  1042.36  1037.09     1029.69  1027.95  1049.76  1041.12\n",
              " 1032.85  1020.61  1031.86  1031.84     1029.17  1025.58  1038.33  1034.66\n",
              " 1033.51  1004.56  1037.56  1013.91     1013.63  1021.88  1036.51  1017.24\n",
              " 1028.97  1017.46  1033.71  1028.78  …  1019.38  1015.61  1034.45  1032.91\n",
              " 1024.38  1006.09  1021.21  1020.32     1013.48  1016.88  1024.25  1023.06\n",
              " 1054.25  1035.79  1047.1   1035.38     1050.19  1037.93  1061.02  1036.99\n",
              "    ⋮                                ⋱                                ⋮\n",
              " 1048.25  1022.12  1033.04  1037.52     1030.92  1028.33  1047.46  1040.37\n",
              " 1022.8   1010.92  1027.25  1020.61  …  1012.62  1026.87  1033.24  1026.06\n",
              " 1037.05  1010.83  1012.94  1027.49     1020.68  1028.83  1030.81  1029.53\n",
              " 1032.94  1000.12  1013.66  1005.56     1009.84  1017.09  1025.02  1019.89\n",
              " 1018.27  1012.95  1016.49  1022.49     1017.54  1018.5   1026.17  1021.44\n",
              " 1030.69  1022.34  1033.0   1027.41     1019.76  1023.69  1035.67  1025.44\n",
              " 1047.15  1025.59  1036.47  1036.0   …  1027.26  1027.51  1044.79  1037.08\n",
              " 1020.52  1012.35  1017.71  1005.59     1013.7   1014.61  1026.08  1024.57\n",
              " 1037.24  1023.32  1038.6   1036.08     1024.73  1040.01  1044.69  1034.03\n",
              " 1036.25  1023.28  1038.58  1025.03     1023.54  1029.25  1041.12  1030.8\n",
              " 1022.35  1002.39  1019.13  1026.1      1014.03  1015.6   1027.43  1023.78\n",
              " 1028.4   1011.89  1017.41  1019.07  …  1014.12  1012.42  1032.69  1016.87"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    A = rand(2^12, 2^12)\n",
        "    A_d = CuArray(A)\n",
        "\n",
        "    @btime $A * $A;\n",
        "    CUDA.@time A_d * A_d;\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wSs-VWgxLvD4",
        "outputId": "e5da084a-69cf-45b5-f2ab-37b38edb5443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1.004 s (3 allocations: 64.00 MiB)\n",
            "  0.775521 seconds (902.11 k CPU allocations: 45.847 MiB) (3 GPU allocations: 64.000 MiB, 0.00% memmgmt time)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096×4096 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
              "  996.087   999.592   998.09   …   988.316  1007.7   1022.01  1007.2\n",
              " 1006.53   1011.06   1023.48      1001.09   1040.52  1041.84  1031.08\n",
              " 1017.01   1008.32   1018.55      1009.75   1027.09  1043.75  1022.13\n",
              " 1019.15   1011.22   1024.76      1021.3    1037.39  1038.91  1025.44\n",
              " 1014.54   1011.69   1031.85      1014.21   1036.06  1039.57  1025.65\n",
              " 1013.87    992.487   999.248  …   999.858  1012.78  1028.95  1012.23\n",
              " 1022.98   1018.57   1022.47      1018.9    1022.3   1039.56  1029.28\n",
              " 1002.36    995.587  1007.21       989.008  1002.11  1011.41  1007.44\n",
              " 1012.87   1011.56   1022.31      1007.16   1020.63  1028.17  1024.57\n",
              " 1005.17    994.774  1005.77       986.332  1010.36  1018.36  1005.56\n",
              " 1012.01   1003.77   1005.64   …  1005.09   1015.53  1041.75  1026.64\n",
              " 1001.91   1006.91   1002.48      1005.54   1021.41  1025.02  1019.69\n",
              "  991.453   996.826  1000.81       992.184  1012.54  1023.66  1000.38\n",
              "    ⋮                          ⋱                                 ⋮\n",
              " 1026.3    1013.76   1030.83      1016.2    1028.56  1048.64  1039.44\n",
              " 1009.41   1007.21   1010.96   …  1006.72   1026.64  1020.0   1015.24\n",
              " 1032.81   1015.73   1041.48      1027.76   1043.34  1054.64  1037.46\n",
              "  985.286   981.982   996.8        981.904  1014.65  1017.65  1015.52\n",
              "  999.356  1011.61   1029.92      1010.83   1033.89  1044.97  1023.28\n",
              "  996.383   993.485  1004.39       991.551  1006.39  1022.39  1003.27\n",
              " 1015.57   1005.21   1022.99   …  1000.49   1018.27  1048.37  1023.94\n",
              " 1032.75   1030.75   1047.02      1021.67   1040.09  1054.35  1038.37\n",
              " 1023.27   1013.32   1021.0       1034.46   1032.59  1044.43  1048.68\n",
              " 1013.1    1003.67   1016.27       999.768  1025.67  1027.68  1027.23\n",
              " 1012.32    998.152  1015.76      1006.82   1014.65  1018.99  1014.48\n",
              "  999.108   997.12   1002.71   …   994.967  1015.06  1024.99  1009.59"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    A = rand(Float32, 2^12, 2^12)\n",
        "    A_d = CuArray(A)\n",
        "    @btime $A * $A\n",
        "    CUDA.@time A_d * A_d\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9gLw9HnLvD4"
      },
      "source": [
        "GPUs normally perform significantly better for 32-bit floats. Some GPUs doesn't support 64-bit floats!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V9iRzyULvD4"
      },
      "source": [
        "Many array operations in Julia are implemented using loops, processing one element at a time. Doing so with GPU arrays is very ineffective, as the loop won't actually execute on the GPU, but transfer one element at a time and process it on the CPU. As this wrecks performance, you will be warned when performing this kind of iteration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g3Ha7KkOLvD5",
        "outputId": "1b2b2d68-96df-4a85-ff78-4bf23644698f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mPerforming scalar indexing on task Task (runnable, started) @0x00007b682b5368b0.\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mInvocation of setindex! resulted in scalar indexing of a GPU array.\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis is typically caused by calling an iterating implementation of a method.\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mand therefore should be avoided.\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIf you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mto enable scalar iteration globally or for the operations in question.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ GPUArraysCore ~/.julia/packages/GPUArraysCore/aNaXo/src/GPUArraysCore.jl:145\u001b[39m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    A_d[1] = 3.0\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve8NM3wJLvD5"
      },
      "source": [
        "Scalar indexing is only allowed in an interactive session, e.g. the REPL, because it is convenient when porting CPU code to the GPU. If you want to disallow scalar indexing, e.g. to verify that your application executes correctly on the GPU, call the allowscalar function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oQpTEb9dLvD5",
        "outputId": "b08d3c3d-4afc-403c-ff94-6008d5196996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mIt's not recommended to use allowscalar([true]) to allow scalar indexing.\n",
            "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mInstead, use `allowscalar() do end` or `@allowscalar` to denote exactly which operations can use scalar operations.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ GPUArraysCore ~/.julia/packages/GPUArraysCore/aNaXo/src/GPUArraysCore.jl:184\u001b[39m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    CUDA.allowscalar()\n",
        "    A_d[1] = 3.0\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwwl65GHLvD5"
      },
      "source": [
        "In a non-interactive session, e.g. when running code from a script or application, scalar indexing is disallowed by default. There is no global toggle to allow scalar indexing; if you really need it, you can mark expressions using allowscalar with do-block syntax or `@allowscalar` macro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LxvDT9sCLvD5",
        "outputId": "340b5089-836c-4266-f357-a166309e02db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0f0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    CUDA.allowscalar(false)\n",
        "\n",
        "    CUDA.allowscalar() do\n",
        "        A_d[1] += 1\n",
        "    end\n",
        "\n",
        "    CUDA.@allowscalar A_d[1] += 1\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNqhiRv9LvD6"
      },
      "source": [
        "Nvidia provides CUDA toolkit, a collection of libraries that contain precompiled kernels for common operations like matrix multiplication ([cuBLAS](https://docs.nvidia.com/cuda/cublas/)), fast Fourier transforms ([cuFFT](https://docs.nvidia.com/cuda/cufft/)), linear solvers ([cuSOLVER](https://docs.nvidia.com/cuda/cusolver/)), sparse linear algebra ([CUSPARSE](https://docs.nvidia.com/cuda/cusparse/)), etc.\n",
        "These kernels are wrapped in CUDA.jl and can be used directly with CuArrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhOTyebILvD6"
      },
      "source": [
        "The recommended way to use CUDA.jl is to let it automatically download an appropriate CUDA toolkit. CUDA.jl will check your driver's capabilities, which versions of CUDA are available for your platform, and automatically download an appropriate artifact containing all the libraries that CUDA.jl supports."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MmXKpAWLvD6"
      },
      "source": [
        "```julia\n",
        "CUDA.set_runtime_version!( v\"11.8\" )\n",
        "```\n",
        "To use a local installation, you can invoke the same API but set the version to `\"local\"`:\n",
        "```julia\n",
        "CUDA.set_runtime_version!( local_toolkit=true )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E5pqCdMFLvD7",
        "outputId": "37fbed0e-9c7c-4da9-fe58-766a7db6f035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA toolchain: \n",
            "- runtime 12.5, local installation\n",
            "- driver 550.54.15 for 13.0\n",
            "- compiler 12.9\n",
            "\n",
            "CUDA libraries: \n",
            "- CUBLAS: 12.5.3\n",
            "- CURAND: 10.3.6\n",
            "- CUFFT: 11.2.3\n",
            "- CUSOLVER: 11.6.3\n",
            "- CUSPARSE: 12.5.1\n",
            "- CUPTI: 2024.2.1 (API 23.0.0)\n",
            "- NVML: 12.0.0+550.54.15\n",
            "\n",
            "Julia packages: \n",
            "- CUDA: 5.8.3\n",
            "- CUDA_Driver_jll: 13.0.1+0\n",
            "- CUDA_Compiler_jll: 0.2.1+0\n",
            "- CUDA_Runtime_jll: 0.19.1+0\n",
            "- CUDA_Runtime_Discovery: 1.0.0\n",
            "\n",
            "Toolchain:\n",
            "- Julia: 1.11.5\n",
            "- LLVM: 16.0.6\n",
            "\n",
            "Preferences:\n",
            "- CUDA_Runtime_jll.version: 12.5.1\n",
            "- CUDA_Runtime_jll.local: true\n",
            "\n",
            "1 device:\n",
            "  0: Tesla T4 (sm_75, 14.283 GiB / 15.000 GiB available)\n"
          ]
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    CUDA.versioninfo()\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8m1ZNrLvD7"
      },
      "source": [
        "Let's do a guided tour of what is inside CUDA.jl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v81pHhBqLvD8"
      },
      "outputs": [],
      "source": [
        "if CUDA.functional()\n",
        "    using CUDA.CUBLAS\n",
        "    using CUDA.CUFFT\n",
        "    using CUDA.CUSOLVER\n",
        "    using CUDA.CUSPARSE\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg3YBlB2LvD8"
      },
      "source": [
        "A powerful way to program GPUs with arrays is through Julia’s higher-order array abstractions.\n",
        "The simple element-wise addition we saw above, `a .+= 1`, is an example of this, but more general constructs can be created with `broadcast`, `map`, `reduce`, `accumulate` etc:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fRFS9oYsLvD8",
        "outputId": "17030d90-a967-4597-d155-7bd79e470b54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096×4096 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
              "  4.0        -0.508248   -0.335083   -0.912087    …  -0.44785    -0.858303\n",
              " -0.852563   -0.893101   -0.321687   -0.23571        -0.604702   -0.834698\n",
              " -0.221156   -0.532528   -0.346107   -0.741136       -0.792318   -0.944039\n",
              " -0.727079   -0.943091   -0.1827     -0.382383       -0.433809   -0.455255\n",
              " -0.88376    -0.353073   -0.78484    -0.403264       -0.645132   -0.550728\n",
              " -0.538295   -0.692474   -0.48064    -0.435903    …  -0.345621   -0.331552\n",
              " -0.0550714  -0.517408   -0.440841   -0.648895       -0.0305568  -0.957892\n",
              " -0.983735   -0.460856   -0.125004   -0.411053       -0.121264   -0.412667\n",
              " -0.766548   -0.546135   -0.762496   -0.181115       -0.0594926  -0.567672\n",
              " -0.461056   -0.312635   -0.778755   -0.434568       -0.802518   -0.861647\n",
              " -0.10338    -0.363496   -0.360205   -0.64806     …  -0.0638976  -0.0796155\n",
              " -0.520788   -0.152382   -0.205976   -0.00538105     -0.597848   -0.860872\n",
              " -0.842006   -0.692116   -0.208375   -0.960882       -0.804358   -0.678759\n",
              "  ⋮                                               ⋱               ⋮\n",
              " -0.65491    -0.704563   -0.0845885  -0.425887       -0.492628   -0.0321724\n",
              " -0.894439   -0.860415   -0.497047   -0.671449    …  -0.242503   -0.61756\n",
              " -0.163299   -0.393274   -0.766965   -0.905035       -0.444256   -0.688983\n",
              " -0.350692   -0.542414   -0.21832    -0.407239       -0.773985   -0.638566\n",
              " -0.992595   -0.0414522  -0.0279455  -0.560533       -0.0708157  -0.152831\n",
              " -0.633082   -0.166251   -0.0560219  -0.823308       -0.787209   -0.854479\n",
              " -0.157565   -0.0978622  -0.466069   -0.699144    …  -0.188686   -0.347094\n",
              " -0.506086   -0.198416   -0.86436    -0.193543       -0.477835   -0.975993\n",
              " -0.27227    -0.965918   -0.142858   -0.169053       -0.802855   -0.578236\n",
              " -0.365218   -0.38562    -0.836447   -0.181083       -0.0197552  -0.255683\n",
              " -0.0719256  -0.0955292  -0.229782   -0.213401       -0.291916   -0.399657\n",
              " -0.539788   -0.258021   -0.432582   -0.290143    …  -0.162144   -0.000256121"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    broadcast(-, A_d, 1)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x4z2aXh6LvD9",
        "outputId": "5aff71e9-9858-4178-f6dc-fa016830e446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096×4096 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
              " 6.0      1.49175  1.66492  1.08791  …  1.6675   1.72558  1.55215  1.1417\n",
              " 1.14744  1.1069   1.67831  1.76429     1.02618  1.21002  1.3953   1.1653\n",
              " 1.77884  1.46747  1.65389  1.25886     1.72794  1.0586   1.20768  1.05596\n",
              " 1.27292  1.05691  1.8173   1.61762     1.42323  1.43254  1.56619  1.54474\n",
              " 1.11624  1.64693  1.21516  1.59674     1.35074  1.20594  1.35487  1.44927\n",
              " 1.46171  1.30753  1.51936  1.5641   …  1.1884   1.91192  1.65438  1.66845\n",
              " 1.94493  1.48259  1.55916  1.35111     1.00937  1.89166  1.96944  1.04211\n",
              " 1.01626  1.53914  1.875    1.58895     1.28885  1.62338  1.87874  1.58733\n",
              " 1.23345  1.45386  1.2375   1.81889     1.36867  1.73993  1.94051  1.43233\n",
              " 1.53894  1.68737  1.22124  1.56543     1.94618  1.99532  1.19748  1.13835\n",
              " 1.89662  1.6365   1.63979  1.35194  …  1.52033  1.96453  1.9361   1.92038\n",
              " 1.47921  1.84762  1.79402  1.99462     1.26965  1.07163  1.40215  1.13913\n",
              " 1.15799  1.30788  1.79162  1.03912     1.29896  1.84451  1.19564  1.32124\n",
              " ⋮                                   ⋱                             ⋮\n",
              " 1.34509  1.29544  1.91541  1.57411     1.60543  1.9198   1.50737  1.96783\n",
              " 1.10556  1.13958  1.50295  1.32855  …  1.07247  1.79371  1.7575   1.38244\n",
              " 1.8367   1.60673  1.23303  1.09497     1.36739  1.58472  1.55574  1.31102\n",
              " 1.64931  1.45759  1.78168  1.59276     1.301    1.61917  1.22601  1.36143\n",
              " 1.00741  1.95855  1.97205  1.43947     1.35892  1.32137  1.92918  1.84717\n",
              " 1.36692  1.83375  1.94398  1.17669     1.72621  1.52623  1.21279  1.14552\n",
              " 1.84244  1.90214  1.53393  1.30086  …  1.10588  1.56906  1.81131  1.65291\n",
              " 1.49391  1.80158  1.13564  1.80646     1.03786  1.92948  1.52216  1.02401\n",
              " 1.72773  1.03408  1.85714  1.83095     1.21091  1.67183  1.19715  1.42176\n",
              " 1.63478  1.61438  1.16355  1.81892     1.66511  1.14718  1.98024  1.74432\n",
              " 1.92807  1.90447  1.77022  1.7866      1.08127  1.49276  1.70808  1.60034\n",
              " 1.46021  1.74198  1.56742  1.70986  …  1.37959  1.08022  1.83786  1.99974"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    map(x -> x+1, A_d)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mZudCy_cLvD9",
        "outputId": "26e5e512-9d91-4f98-8e22-963886f83411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.386694f6"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    reduce(+, A_d)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WsqZ756lLvD9",
        "outputId": "eea2d3cc-7e4f-4232-a66d-11b1981f98e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096×4096 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
              "    5.0      2027.4   4040.62  6077.33  …  8.38053f6  8.38258f6  8.38465f6\n",
              "    5.14744  2027.51  4041.29  6078.09     8.38053f6  8.38258f6  8.38465f6\n",
              "    5.92628  2027.97  4041.95  6078.35     8.38053f6  8.38258f6  8.38465f6\n",
              "    6.1992   2028.03  4042.76  6078.97     8.38053f6  8.38258f6  8.38465f6\n",
              "    6.31544  2028.68  4042.98  6079.57     8.38053f6  8.38258f6  8.38465f6\n",
              "    6.77715  2028.99  4043.5   6080.13  …  8.38053f6  8.38258f6  8.38465f6\n",
              "    7.72208  2029.47  4044.06  6080.48     8.38053f6  8.38258f6  8.38465f6\n",
              "    7.73834  2030.01  4044.93  6081.07     8.38053f6  8.38258f6  8.38465f6\n",
              "    7.97179  2030.46  4045.17  6081.89     8.38053f6  8.38258f6  8.38465f6\n",
              "    8.51074  2031.15  4045.39  6082.46     8.38054f6  8.38258f6  8.38465f6\n",
              "    9.40736  2031.79  4046.03  6082.81  …  8.38054f6  8.38258f6  8.38465f6\n",
              "    9.88657  2032.63  4046.83  6083.8      8.38054f6  8.38258f6  8.38465f6\n",
              "   10.0446   2032.94  4047.62  6083.84     8.38054f6  8.38258f6  8.38465f6\n",
              "    ⋮                                   ⋱                        ⋮\n",
              " 2020.86     4032.96  6070.78  8116.21     8.38257f6  8.38464f6  8.38669f6\n",
              " 2020.96     4033.09  6071.28  8116.54  …  8.38257f6  8.38464f6  8.38669f6\n",
              " 2021.8      4033.7   6071.52  8116.64     8.38257f6  8.38464f6  8.38669f6\n",
              " 2022.45     4034.16  6072.3   8117.23     8.38257f6  8.38464f6  8.38669f6\n",
              " 2022.45     4035.12  6073.27  8117.67     8.38257f6  8.38464f6  8.38669f6\n",
              " 2022.82     4035.95  6074.21  8117.84     8.38257f6  8.38464f6  8.38669f6\n",
              " 2023.66     4036.85  6074.75  8118.15  …  8.38257f6  8.38464f6  8.38669f6\n",
              " 2024.16     4037.66  6074.88  8118.95     8.38258f6  8.38464f6  8.38669f6\n",
              " 2024.89     4037.69  6075.74  8119.78     8.38258f6  8.38464f6  8.38669f6\n",
              " 2025.52     4038.3   6075.9   8120.6      8.38258f6  8.38464f6  8.38669f6\n",
              " 2026.45     4039.21  6076.67  8121.39     8.38258f6  8.38464f6  8.38669f6\n",
              " 2026.91     4039.95  6077.24  8122.1   …  8.38258f6  8.38465f6  8.38669f6"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    accumulate(+, A_d)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKHzGdHFLvD9"
      },
      "source": [
        "Using the high-level GPU array functionality made it easy to perform this computation on the GPU. However, we didn't learn about what's going on under the hood, and that's the main goal of this tutorial. It's time to write our own kernels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WPKv4NVALvD-",
        "outputId": "8147703c-6fff-452a-b59d-f5443faa87a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vadd! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "function vadd!(C, A, B)\n",
        "    for i in 1:length(A)\n",
        "        @inbounds C[i] = A[i] + B[i]\n",
        "    end\n",
        "    return nothing\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NiHNyA5ILvD_",
        "outputId": "88e74dc0-f18f-4a6c-e30e-f19ab867ae69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10-element Vector{Float64}:\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "A = ones(10)\n",
        "B = ones(10)\n",
        "C = similar(B)\n",
        "vadd!(C, A, B)\n",
        "C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6z1rXXEXLvD_",
        "outputId": "20396941-6e8b-400d-df14-1c8e4302f296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10-element CuArray{Float64, 1, CUDA.DeviceMemory}:\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0\n",
              " 2.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    # We can already run this on the GPU with the @cuda macro,\n",
        "    # which will compile vadd!() into a GPU kernel and launch it\n",
        "    A_d = CuArray(A)\n",
        "    B_d = CuArray(B)\n",
        "    C_d = similar(B_d)\n",
        "    @cuda vadd!(C_d, A_d, B_d)\n",
        "    C_d\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe6IYb9xLvEA"
      },
      "source": [
        "The macros for the other GPU backends are `@roc`, `@oneapi` and `@metal`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAdyZaUzLvEA"
      },
      "source": [
        "The performance are just terrible because each thread on the GPU would be performing the same loop! So we have to remove the loop over all elements and instead use the special `threadIdx` and `blockDim` functions, analogous respectively to `threadid` and `nthreads` for multithreading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvNZCRJLLvEA"
      },
      "source": [
        "We can split work between the GPU threads by using a special function which returns the index of the GPU thread which executes it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYUOIEDeLvEB"
      },
      "source": [
        "**GPU kernel**: a function that will be executed by all *GPU threads* in parallel.\n",
        "    \n",
        "Based on the index of a thread we can make them operate on different pieces of give n data.\n",
        "\n",
        "(It might be helpful to think of the GPU kernel as being the body of a loop.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ftPkKEabLvEB",
        "outputId": "b2a4dc36-5682-4c90-d286-b67470470ac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vadd2! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "function vadd2!(C, A, B)\n",
        "    index = threadIdx().x   # linear indexing, so only use `x`\n",
        "    @inbounds C[index] = A[index] + B[index]\n",
        "    return nothing\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ktg5ngjRLvEC",
        "outputId": "bb484e2e-df78-4d7a-e492-eaf16acc7c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUDA.HostKernel for vadd2!(CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    N = 2^8\n",
        "    A = 2 * CUDA.ones(N)\n",
        "    B = 3 * CUDA.ones(N)\n",
        "    C = similar(B)\n",
        "\n",
        "    nthreads = N\n",
        "    @cuda threads=nthreads vadd2!(C, A, B)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PABnUgNCLvEC",
        "outputId": "6cf723ae-f7de-4628-e2f3-3e480149fefb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "true"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    all(Array(C) .== 5.0)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfMXSKyGLvEC"
      },
      "source": [
        "The syntax is similar for the other GPU backends!\n",
        "```julia\n",
        "groupsize = length(A)\n",
        "@roc groupsize=groupsize vadd!(C, A, B)\n",
        "\n",
        "items = length(A)\n",
        "@oneapi items=items vadd!(C, A, B)\n",
        "\n",
        "nthreads = length(A)\n",
        "@metal threads=nthreads vadd!(C, A, B)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeAEt7BBLvED"
      },
      "source": [
        "To do even better, we need to parallelize more. GPUs have a limited number of threads they can run on a single streaming multiprocessor (SM), but they also have multiple SMs. To take advantage of them all, we need to run a kernel with multiple blocks. We'll divide up the work like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOUtRQRnLvED"
      },
      "source": [
        "![gpu_threads_block](https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/gpu_threads_block.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmwkLP40LvED"
      },
      "source": [
        "Conceptual mapping:\n",
        "\n",
        "* **Grid** of blocks → entire GPU\n",
        "* **Blocks** of threads → SMs\n",
        "* **Threads** → CUDA cores\n",
        "\n",
        "**Note**: up to three dimensions, $(x, y, z)$, can be used to organize the thread blocks and threads in each block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ANSj4NLvEE"
      },
      "source": [
        "This diagram was borrowed from a description of the NVIDIA C/C++ library; in Julia, threads and blocks begin numbering with 1 instead of 0. In this diagram, the 4096 blocks of 256 threads (making 1048576 = 2^20 threads) ensures that each thread increments just a single entry; however, to ensure that arrays of arbitrary size can be handled, let's still use a loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qQREsV9ELvEE",
        "outputId": "826a2b7c-d3f4-4cfc-9932-eb726c10d2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vadd3! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "function vadd3!(C, A, B)\n",
        "    index = threadIdx().x + (blockIdx().x - 1) * blockDim().x\n",
        "    stride = gridDim().x * blockDim().x\n",
        "    for i = index:stride:length(B)\n",
        "        @inbounds C[index] = A[index] + B[index]\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Jg5ksR8KLvEE",
        "outputId": "37a6ddb5-bae9-4441-fd00-fb6f1dfa13ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    nthreads = CUDA.attribute(device(), CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4W6NFHwLvEF"
      },
      "source": [
        "The maximum number of allowed threads to launch depends on your GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EmoAXAYTLvEF",
        "outputId": "f362ace3-4c34-49a7-c05e-d969dc486662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    N = 2^14\n",
        "    A = 2 * CUDA.ones(N)\n",
        "    B = 3 * CUDA.ones(N)\n",
        "    C = similar(B)\n",
        "\n",
        "    # smallest integer larger than or equal to N / nthreads\n",
        "    numblocks = ceil(Int, N/nthreads)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9EyUgkcaLvEF",
        "outputId": "8624d56e-67b6-4869-d3eb-67ba723e090c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUDA.HostKernel for vadd3!(CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "if CUDA.functional()\n",
        "    @cuda threads=nthreads blocks=numblocks vadd3!(C, A, B)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "N2YLl-X_LvEF",
        "outputId": "9fc8142a-e2e2-4bab-9cc2-0b5f2c1c6b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "true"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        " all(Array(C) .== 5.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zr9iwEfLvEF"
      },
      "source": [
        "CUDA.jl supports indexing in up to 3 dimensions (x, y and z, e.g. `threadIdx().z`). This is convenient for multidimensional data where thread blocks can be organised into 1D, 2D or 3D arrays of threads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRyJ_L6ELvEG"
      },
      "source": [
        "To automatically select an appropriate number of threads, it is recommended to use the launch configuration API. This API takes a compiled (but not launched) kernel, returns a tuple with an upper bound on the number of threads, and the minimum number of blocks that are required to fully saturate the GPU:\n",
        "\n",
        "To optimize the number of threads, we can first create the kernel without launching it, query it for the number of threads supported, and then launch the compiled kernel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-isX_E4XLvEH"
      },
      "outputs": [],
      "source": [
        "# compile kernel\n",
        "kernel = @cuda launch=false vadd3!(C, A, B)\n",
        "\n",
        "# extract configuration via occupancy API\n",
        "config = launch_configuration(kernel.fun)\n",
        "\n",
        "# number of threads should not exceed size of array\n",
        "threads = min(length(A), config.threads)\n",
        "\n",
        "# smallest integer larger than or equal to length(A)/threads\n",
        "blocks = cld(length(A), threads)\n",
        "\n",
        "# launch kernel with specific configuration\n",
        "kernel(C, A, B; threads, blocks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CikQMWgRLvEI"
      },
      "source": [
        "**Debugging**: Many things can go wrong with GPU kernel programming and unfortunately error messages are sometimes not very useful because of how the GPU compiler works.\n",
        "\n",
        "Conventional print-debugging is often a reasonably effective way to debug GPU code. CUDA.jl provides macros that facilitate this:\n",
        "- `@cushow` (like @show): visualize an expression and its result, and return that value.\n",
        "- `@cuprintln` (like println): to print text and values.\n",
        "- `@cuaassert` (like @assert) can also be useful to find issues and abort execution.\n",
        "\n",
        "GPU code introspection macros also exist, like `@device_code_warntype`, to track down type instabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "08ExTo_7LvEI",
        "outputId": "247ec3aa-bb7e-4c78-a52d-4656adea473b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thread 1, block 10\n",
            "thread 2, block 10\n",
            "thread 3, block 10\n",
            "thread 4, block 10\n",
            "thread 5, block 10\n",
            "thread 6, block 10\n",
            "thread 7, block 10\n",
            "thread 8, block 10\n",
            "thread 9, block 10\n",
            "thread 10, block 10\n"
          ]
        }
      ],
      "source": [
        "function gpu_add_print!(y, x)\n",
        "    index = threadIdx().x    # this example only requires linear indexing, so just use `x`\n",
        "    stride = blockDim().x\n",
        "    @cuprintln(\"thread $index, block $stride\")\n",
        "    for i = index:stride:length(y)\n",
        "        @inbounds y[i] += x[i]\n",
        "    end\n",
        "    return nothing\n",
        "end\n",
        "\n",
        "if CUDA.functional()\n",
        "    x_d = CUDA.rand(10)\n",
        "    y_d = CUDA.rand(10)\n",
        "    @cuda threads=10 gpu_add_print!(y_d, x_d)\n",
        "    synchronize()\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnrYd8HALvEJ"
      },
      "source": [
        "**Conclusion**: Keep in mind that the high-level functionality of CUDA often means that you don't need to worry about writing kernels at such a low level. However, there are many cases where computations can be optimized using clever low-level manipulations. The kernels implemented in Julia give you all the flexibility and performance a GPU has to offer, within a familiar language.\n",
        "\n",
        "A typical approach for porting or developing an application for the GPU is as follows:\n",
        "- develop an application using generic array functionality, and test it on the CPU with the `Array` type;\n",
        "- port your application to the GPU by switching to the `CuArray` type;\n",
        "- disallow the CPU fallback (\"scalar indexing\") to find operations that are not implemented for or incompatible with GPU execution;\n",
        "- (optional) use lower-level, CUDA-specific interfaces to implement missing functionality or optimize performance.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXV_ClsDLvEK"
      },
      "source": [
        "**Exercise**: GPU-port the `sqrt_sum` function we saw in te first notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zTsMz8yILvEK",
        "outputId": "b523a89a-ee99-4ba9-ae6a-c6a691c2de54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sqrt_sum (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "function sqrt_sum(A)\n",
        "    T = eltype(A)\n",
        "    s = zero(T)\n",
        "    for i in eachindex(A)\n",
        "        @inbounds s += sqrt(A[i])\n",
        "    end\n",
        "    return s\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQKm4aGTLvEL"
      },
      "source": [
        "# References:\n",
        "- https://cuda.juliagpu.org/stable/\n",
        "- https://www.youtube.com/watch?v=Fz-ogmASMAE\n",
        "- https://www.cherryservers.com/blog/gpu-vs-cpu-what-are-the-key-differences\n",
        "- https://developer.nvidia.com/blog/tag/cuda-refresher/\n",
        "- https://docs.nvidia.com/cuda/\n",
        "- https://www.youtube.com/watch?v=Hz9IMJuW5hU\n",
        "- https://julialang.org/learning/"
      ]
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}