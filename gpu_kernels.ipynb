{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/amontoison/Workshop-GERAD/blob/main/gpu_kernels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjJTIwxxJjwX"
   },
   "source": [
    "# Parallel computing and GPU programming with Julia\n",
    "## Part IV: GPU Kernels with KernelAbstractions.jl\n",
    "Alexis Montoison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSgoDg8fFyEp",
    "outputId": "24d9fea9-a0f6-4ffc-81a1-6eda492ec0e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `/content/@colab`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ImageShow ────────── v0.3.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ───── v1.6.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AcceleratedKernels ─ v0.4.3\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/content/@colab/Project.toml`\n",
      "  \u001b[90m[6a4ca0a5] \u001b[39m\u001b[92m+ AcceleratedKernels v0.4.3\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.3.0\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.2\u001b[39m\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
      "  \u001b[90m[052768ef] \u001b[39m\u001b[92m+ CUDA v5.8.3\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.38\u001b[39m\n",
      "  \u001b[90m[5da4648a] \u001b[39m\u001b[92m+ NVTX v1.0.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/content/@colab/Manifest.toml`\n",
      "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
      "  \u001b[90m[6a4ca0a5] \u001b[39m\u001b[92m+ AcceleratedKernels v0.4.3\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.3.0\u001b[39m\n",
      "  \u001b[90m[dce04be8] \u001b[39m\u001b[92m+ ArgCheck v2.5.0\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.2\u001b[39m\n",
      "  \u001b[90m[ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.5.1\u001b[39m\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
      "  \u001b[90m[fa961155] \u001b[39m\u001b[92m+ CEnum v0.5.0\u001b[39m\n",
      "  \u001b[90m[052768ef] \u001b[39m\u001b[92m+ CUDA v5.8.3\u001b[39m\n",
      "  \u001b[90m[1af6417a] \u001b[39m\u001b[92m+ CUDA_Runtime_Discovery v1.0.0\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.31.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.1\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.1\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.18.0\u001b[39m\n",
      "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.8.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.19.1\u001b[39m\n",
      "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
      "  \u001b[90m[e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.10\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.17.0\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v11.2.5\u001b[39m\n",
      "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
      "  \u001b[90m[61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v1.6.1\u001b[39m\n",
      "  \u001b[90m[096a3bc2] \u001b[39m\u001b[92m+ GPUToolbox v0.3.0\u001b[39m\n",
      "  \u001b[90m[076d061b] \u001b[39m\u001b[92m+ HashArrayMappedTries v0.2.0\u001b[39m\n",
      "  \u001b[90m[c817782e] \u001b[39m\u001b[92m+ ImageBase v0.1.7\u001b[39m\n",
      "  \u001b[90m[a09fc81d] \u001b[39m\u001b[92m+ ImageCore v0.10.5\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[842dd82b] \u001b[39m\u001b[92m+ InlineStrings v1.4.5\u001b[39m\n",
      "  \u001b[90m[41ab1584] \u001b[39m\u001b[92m+ InvertedIndices v1.3.1\u001b[39m\n",
      "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.1\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.38\u001b[39m\n",
      "  \u001b[90m[929cbde3] \u001b[39m\u001b[92m+ LLVM v9.4.2\u001b[39m\n",
      "  \u001b[90m[8b046642] \u001b[39m\u001b[92m+ LLVMLoopInfo v1.0.0\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.16\u001b[39m\n",
      "  \u001b[90m[dbb5928d] \u001b[39m\u001b[92m+ MappedArrays v0.4.2\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[e94cdb99] \u001b[39m\u001b[92m+ MosaicViews v0.3.4\u001b[39m\n",
      "  \u001b[90m[5da4648a] \u001b[39m\u001b[92m+ NVTX v1.0.1\u001b[39m\n",
      "  \u001b[90m[6fe1bfb0] \u001b[39m\u001b[92m+ OffsetArrays v1.17.0\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.1\u001b[39m\n",
      "  \u001b[90m[5432bcbf] \u001b[39m\u001b[92m+ PaddedViews v0.5.12\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.3\u001b[39m\n",
      "  \u001b[90m[2dfb63ee] \u001b[39m\u001b[92m+ PooledArrays v1.4.3\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.5.0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
      "  \u001b[90m[74087812] \u001b[39m\u001b[92m+ Random123 v1.7.1\u001b[39m\n",
      "  \u001b[90m[e6cf234a] \u001b[39m\u001b[92m+ RandomNumbers v1.6.0\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
      "  \u001b[90m[7e506255] \u001b[39m\u001b[92m+ ScopedValues v1.5.0\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.3.0\u001b[39m\n",
      "  \u001b[90m[91c51154] \u001b[39m\u001b[92m+ SentinelArrays v1.4.8\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.2\u001b[39m\n",
      "  \u001b[90m[cae243ae] \u001b[39m\u001b[92m+ StackViews v0.1.2\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.15\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.3\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[892a3eda] \u001b[39m\u001b[92m+ StringManipulation v0.4.1\u001b[39m\n",
      "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
      "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.1\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[e689c965] \u001b[39m\u001b[92m+ Tracy v0.1.6\u001b[39m\n",
      "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
      "  \u001b[90m[d1e2174e] \u001b[39m\u001b[92m+ CUDA_Compiler_jll v0.2.1+0\u001b[39m\n",
      "  \u001b[90m[4ee394cb] \u001b[39m\u001b[92m+ CUDA_Driver_jll v13.0.1+0\u001b[39m\n",
      "  \u001b[90m[76a88914] \u001b[39m\u001b[92m+ CUDA_Runtime_jll v0.19.1+0\u001b[39m\n",
      "  \u001b[90m[9c1d0b0a] \u001b[39m\u001b[92m+ JuliaNVTXCallbacks_jll v0.2.1+0\u001b[39m\n",
      "  \u001b[90m[dad2f222] \u001b[39m\u001b[92m+ LLVMExtra_jll v0.0.37+2\u001b[39m\n",
      "  \u001b[90m[ad6e5548] \u001b[39m\u001b[92m+ LibTracyClient_jll v0.9.1+6\u001b[39m\n",
      "  \u001b[90m[e98f9f5b] \u001b[39m\u001b[92m+ NVTX_jll v3.2.2+0\u001b[39m\n",
      "  \u001b[90m[1e29f10c] \u001b[39m\u001b[92m+ demumble_jll v1.3.0+0\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.11.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.11.0\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.1.1+0\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.6.0+0\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.7.2+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.6+0\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2023.12.12\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.27+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.7.0+0\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+1\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.11.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.59.0+0\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+2\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "   3827.8 ms\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
      "   5190.3 ms\u001b[32m  ✓ \u001b[39mImageShow\n",
      "   5539.5 ms\u001b[32m  ✓ \u001b[39mAcceleratedKernels\n",
      "  3 dependencies successfully precompiled in 9 seconds. 120 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"@colab\")\n",
    "Pkg.add([\n",
    "    \"CUDA\",\n",
    "    \"KernelAbstractions\",\n",
    "    \"Atomix\",\n",
    "    \"AcceleratedKernels\",\n",
    "    \"BenchmarkTools\",\n",
    "    \"Adapt\",\n",
    "    \"NVTX\",\n",
    "    \"ImageShow\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJdnRZwNF2fh",
    "outputId": "3a36f4c1-e9e3-4957-c985-d9bf3882ba24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.10.9\n",
      "Commit 5595d20a287 (2025-03-10 12:51 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-15.0.7 (ORCJIT, skylake-avx512)\n",
      "Threads: 2 default, 0 interactive, 1 GC (on 2 virtual cores)\n",
      "Environment:\n",
      "  LD_LIBRARY_PATH = /usr/lib64-nvidia\n",
      "  JULIA_NUM_THREADS = auto\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ru_R_unVF8JR"
   },
   "outputs": [],
   "source": [
    "using CUDA, KernelAbstractions, Adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJThsWC1Jjwk"
   },
   "source": [
    "### Different layers of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fURgDPvJjwl"
   },
   "source": [
    "#### Vendor-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8i8b3ZtJjwm"
   },
   "outputs": [],
   "source": [
    "function saxpy!(a,X,Y)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    if i <= length(Y)\n",
    "        @inbounds Y[i] = a * X[i] + Y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@cuda threads=32 blocks=cld(length(Y), 32) saxpy!(a, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlA94N55Jjwn"
   },
   "source": [
    "#### KernelAbstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLaCJWFYJjwo"
   },
   "outputs": [],
   "source": [
    "using KernelAbstractions\n",
    "using CUDA\n",
    "\n",
    "@kernel function saxpy!(a, @Const(X), Y)\n",
    "    I = @index(Global)\n",
    "    @inbounds Y[I] = a * X[I] + Y[I]\n",
    "end\n",
    "\n",
    "saxpy!(CUDABackend())(a, X, Y, ndrange=length(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Co2nDQkJjwr"
   },
   "source": [
    "#### Array abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MD_tILRJjwr"
   },
   "outputs": [],
   "source": [
    "Y .= a .* X .+ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-ZB0lDaJjwt"
   },
   "source": [
    "#### How to use KernelAbstractions\n",
    "\n",
    "- Use `@kernel function mykernel(args...) end` to write a GPU-style program\n",
    "- Instantiate kernel for a backend `kernel = mykernel(backend)`\n",
    "- Backends come from Vendor specific libraries\n",
    "- `KA.allocate(backend, ...)` to obtain memory\n",
    "- Launch kernel `kernel(args..., ndrange=...)` while specifying the grid to execute over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCjiqBQQJjwv"
   },
   "outputs": [],
   "source": [
    "function vadd(a, b, c)\n",
    "    for i in eachindex(c)\n",
    "        c[i] = a[i] + b[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "a = rand(N)\n",
    "b = rand(N)\n",
    "c = similar(a)\n",
    "\n",
    "vadd(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zxhl2gcyJjwv"
   },
   "outputs": [],
   "source": [
    "import KernelAbstractions as KA\n",
    "\n",
    "@kernel function vadd(a, b, c)\n",
    "    i = @index(Global)\n",
    "    c[i] = a[i] + b[i]\n",
    "end\n",
    "\n",
    "backend = CUDABackend()\n",
    "a = KA.allocate(backend, Float32, N)\n",
    "b = KA.allocate(backend, Float32, N)\n",
    "c = similar(a)\n",
    "\n",
    "vadd_kernel = vadd(backend)\n",
    "vadd_kernel(a, b, c; ndrange=size(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcXK1M6TJjwv"
   },
   "source": [
    "#### Asynchronous operations\n",
    "\n",
    "GPU operations are asynchronous with regards to the host! They are **ordered** with respect to each other, but special care must be taken when using Julia's task based programming together with GPU programming.\n",
    "\n",
    "The JuliaGPU ecosystem **synchronizes** the GPU on access, so when you move data from and to the GPU we wait for all the kernels to finish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zfgVGjrJjww"
   },
   "source": [
    "When benchmarking you need to synchronize the device!\n",
    "\n",
    "```julia\n",
    "@benchmark begin\n",
    "    vadd_kernel(a, b, c; ndrange=size(c))\n",
    "    KA.synchronize(backend)\n",
    "end\n",
    "```\n",
    "\n",
    "Otherwise you are only measuring the **launch** of the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srAt0_5xJjwy"
   },
   "source": [
    "### High-level array based programming\n",
    "\n",
    "Julia and GPUArrays.jl provide support for an efficient GPU programming environment build around array abstractions and higher-order functions.\n",
    "\n",
    "- **Vocabulary of operations**: `map`, `broadcast`, `scan`, `reduce`, ...\n",
    "  Map naturally onto GPU execution models\n",
    "- **Compiled to efficient code**: multiple dispatch, specialization\n",
    "  Write generic, reusable applications\n",
    "- BLAS (matrix-multiply, ...), and other libraries like FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zllUJ-bjJjwy"
   },
   "source": [
    "Array types -- **where** memory resides and **how** code is executed.\n",
    "Note that data movement is explicit.\n",
    "\n",
    "|  |  |\n",
    "| --- | --- |\n",
    "|  `A = Matrix{Float64}(undef, 64, 32)`   | CPU   |\n",
    "|  `A = CuMatrix{Float64}(undef, 64, 32)`   | Nvidia GPU   |\n",
    "|  `A = ROCMatrix{Float64}(undef, 64, 32)`   | AMD GPU   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LW51Tc5Jjwz"
   },
   "source": [
    "### What makes an application portable?\n",
    "\n",
    "1. Can I **run** it on a different compute architecture\n",
    "    1. Different CPU architectures\n",
    "    2. We live in a mult GPU vendor world\n",
    "2. Does it **compute** the same thing?\n",
    "    1. Can I develop on one platform and move to another later?\n",
    "3. Does it achieve the same **performance**?\n",
    "4. Can I take advantage of platform **specific** capabilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEawmex5Jjw0"
   },
   "source": [
    "#### Adapt.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsLBPf2nJjw0"
   },
   "source": [
    "[Adapt.jl](https://github.com/JuliaGPU/Adapt.jl) is a lightweight dependency that you can use to convert complex structures from CPU to GPU.\n",
    "\n",
    "```julia\n",
    "using Adapt\n",
    "adapt(CuArray, ::Adjoint{Array})::Adjoint{CuArray}\n",
    "```\n",
    "\n",
    "```julia\n",
    "struct Model{T<:Number, AT<:AbstractArray{T}}\n",
    "   data::AT\n",
    "end\n",
    "\n",
    "Adapt.adapt_structure(to, x::Model) = Model(adapt(to, x.data))\n",
    "\n",
    "cpu = Model(rand(64, 64));\n",
    "using CUDA\n",
    "\n",
    "gpu = adapt(CuArray, cpu)\n",
    "Model{Float64, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}}(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP-7j9lYMSrc"
   },
   "source": [
    "## A first GPU kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9to6RnQBMaWI",
    "outputId": "fa267f65-99fa-4c0a-c9a8-6a37b23464a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_cpu! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_cpu!(A, B)\n",
    "  for I in 1:length(A)\n",
    "    @inbounds A[I] = B[I]\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgeKBnvaMp_K",
    "outputId": "0374f71f-ce46-4735-fb20-ad2b486c6a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function copy_kernel!(A, B)\n",
    "  I = @index(Global)\n",
    "  @inbounds A[I] = B[I]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-p6C7VlMtbv",
    "outputId": "0398c224-2b53-4bf0-eeb7-3ef91c64d766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_ka! (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_ka!(A, B)\n",
    "  backend = get_backend(A)\n",
    "  @assert size(A) == size(B)\n",
    "  @assert get_backend(B) == backend\n",
    "\n",
    "  kernel = copy_kernel!(backend)\n",
    "  kernel(A, B, ndrange = length(A))\n",
    "  return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjt_75UzPWz3"
   },
   "outputs": [],
   "source": [
    "using CUDA: i32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xtUFmO4PFD6",
    "outputId": "5921503e-e062-4a83-f67d-8fbcefc426e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_kernel_cuda! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_kernel_cuda!(A, B)\n",
    "  I = (blockIdx().x-1i32) * blockDim().x + threadIdx().x\n",
    "  if I <= length(A)\n",
    "      @inbounds A[I] = B[I]\n",
    "  end\n",
    "  return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HykWeqPYM3O4",
    "outputId": "b0fd1838-8f57-4e50-eca9-287065589cec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_cuda! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_cuda!(A, B)\n",
    "  kernel = @cuda launch=false copy_kernel_cuda!(A, B)\n",
    "  config = launch_configuration(kernel.fun)\n",
    "  threads = min(length(A), config.threads)\n",
    "  blocks = cld(length(A), threads)\n",
    "\n",
    "  kernel(A, B; threads, blocks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiQw4-ZsNX09"
   },
   "outputs": [],
   "source": [
    "B = rand(64_000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NomJoN_cN8j8"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  A = similar(B)\n",
    "  copy_cpu!(A, B)\n",
    "  @assert A == B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTn9RZViOK7E"
   },
   "source": [
    "Julia GPU ecosystem follows the motto: Compute follows Data\n",
    "\n",
    "So let's move our data to the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeFIdqtoOVpn"
   },
   "outputs": [],
   "source": [
    "d_B = adapt(CuArray, B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mGdoaInOmG1",
    "outputId": "ea9e7eeb-785c-465c-be6c-55eeea8fc150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuArray{Float64, 1, CUDA.DeviceMemory}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(d_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CH-SW0koOHe7"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  d_A = similar(d_B)\n",
    "  copy_cuda!(d_A, d_B)\n",
    "  @assert d_A == d_B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKpr9veGPeJn"
   },
   "source": [
    "Note that Julia GPU Ecosystem, synchronizes the GPU on access. So we are launchign two GPU kernels here, first the copy, then the comparision and they are both executing asynchronously, but ordered with respect to each other.\n",
    "\n",
    "We then \"wait\" for the result of the comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQawEsBoPdNx"
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVmA2-2XP81s",
    "outputId": "1fce7b1c-b8c8-49aa-de34-d93db72a26ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 6 evaluations per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m5.686 μs\u001b[22m\u001b[39m … \u001b[35m 16.612 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m6.044 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m6.248 μs\u001b[22m\u001b[39m ± \u001b[32m780.293 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[32m▅\u001b[39m\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  5.69 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      10.2 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m720 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m28\u001b[39m."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark copy_cuda!(d_A, $d_B) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_iWSWoFQR8l",
    "outputId": "b7819aaf-1d42-416e-a0be-24eb728db0dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 270.84 µs, capturing 261 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 119.92 µs (44.28% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                   │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   27.64% │\u001b[31m   74.86 µs │    10 │   7.49 µs ± 9.96   (  3.58 ‥ 35.76) │\u001b[1m cuLaunchKernel          │\n",
       "│    4.40% │   11.92 µs │     1 │                                     │ cuMemAllocFromPoolAsync │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 56.03 µs (20.69% of the trace)\n",
       "┌──────────┬────────────┬───────┬────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                  │\u001b[1m Name                                                                          │\n",
       "├──────────┼────────────┼───────┼────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤\n",
       "│   20.69% │\u001b[31m   56.03 µs │    10 │    5.6 µs ± 0.59   (  5.25 ‥ 7.15) │\u001b[1m copy_kernel_cuda_(CuDeviceArray<Float64, 1, 1>, CuDeviceArray<Float64, 1, 1>) │\n",
       "└──────────┴────────────┴───────┴────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile let\n",
    "  d_A = similar(d_B)\n",
    "  for _ in 1:10\n",
    "    copy_cuda!(d_A, d_B)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDtBttwaQlRq"
   },
   "source": [
    "So there seems to be a discrepancy between the measurement of `@benchmark` and `CUDA.@profile`, `@benchmark` seems to vastly over-estimate the performance of the GPU code. To remedy this we need to include a synchronization operation with benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcXwhR-nQklV",
    "outputId": "00ee47ab-b21f-4808-c9fb-ae205d79ae88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m19.916 μs\u001b[22m\u001b[39m … \u001b[35m104.479 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m21.002 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m21.472 μs\u001b[22m\u001b[39m ± \u001b[32m  2.380 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m▅\u001b[39m\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  19.9 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      31.4 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m720 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m28\u001b[39m."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync(copy_cuda!(d_A, $d_B)) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfM7FARLRQ7P"
   },
   "source": [
    "With KernelAbstractions we can now write code that is portable and can be used both for data that resides on the CPU as well as the GPU, therefore implementing the \"Compute follows Data\" paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFRjXDPgRhdp"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  A = similar(B)\n",
    "  copy_ka!(A, B)\n",
    "  @assert A == B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAiptA8FRhHX"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  d_A = similar(d_B)\n",
    "  copy_ka!(d_A, d_B)\n",
    "  @assert d_A == d_B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1_l8pGvRvPm",
    "outputId": "da729235-93e9-4aad-b49d-f6d90fccfad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m108.141 μs\u001b[22m\u001b[39m … \u001b[35m  7.116 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m126.832 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m186.821 μs\u001b[22m\u001b[39m ± \u001b[32m128.714 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[34m▆\u001b[39m\u001b[39m▄\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[32m▄\u001b[39m\u001b[39m▅\u001b[39m▆\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  108 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        435 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.83 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m33\u001b[39m."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark copy_ka!(A, $B) setup=(A = similar(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IyrrlbHRulN",
    "outputId": "2c750443-8c9f-40fb-f5c1-8dc0c6bbc8b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m24.232 μs\u001b[22m\u001b[39m … \u001b[35m 8.109 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m25.365 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m27.597 μs\u001b[22m\u001b[39m ± \u001b[32m84.574 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m▆\u001b[39m▅\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  24.2 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      46.6 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.62 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m60\u001b[39m."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync(copy_ka!(d_A, $d_B)) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5LYIpSySgxC",
    "outputId": "4336f30f-bd14-4131-b6da-08879190a33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 333.31 µs, capturing 261 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 105.62 µs (31.69% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                   │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   21.03% │\u001b[31m    70.1 µs │    10 │   7.01 µs ± 7.78   (  3.81 ‥ 29.09) │\u001b[1m cuLaunchKernel          │\n",
       "│    1.50% │    5.01 µs │     1 │                                     │ cuMemAllocFromPoolAsync │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 59.13 µs (17.74% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                 │\u001b[1m Name                                                                                                                                                                                                                                                                                                │\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   17.74% │\u001b[31m   59.13 µs │    10 │   5.91 µs ± 0.22   (  5.48 ‥ 6.2) │\u001b[1m gpu_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<1, Tuple<OneTo<Int64>>>, NDRange<1, DynamicSize, DynamicSize, CartesianIndices<1, Tuple<OneTo<Int64>>>, CartesianIndices<1, Tuple<OneTo<Int64>>>>>, CuDeviceArray<Float64, 1, 1>, CuDeviceArray<Float64, 1, 1>) │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile let\n",
    "  d_A = similar(d_B)\n",
    "  for _ in 1:10\n",
    "    copy_ka!(d_A, d_B)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QDwG01WSwS4"
   },
   "source": [
    "We can see that KernelAbstractions is a bit slower than pure CUDA, and that is partially expected due to some convenience functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDnLIOGdSuJd",
    "outputId": "772cef28-8673-49a5-a8c8-84073baed210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_kernel_faster! (generic function with 4 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel unsafe_indices=true function copy_kernel_faster!(A, B)\n",
    "  N = @uniform prod(@groupsize())\n",
    "  I = (@index(Group, Linear)-1i32) * N + @index(Local, Linear)\n",
    "  if I <= length(A)\n",
    "    @inbounds A[I] = B[I]\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DjrhOH5TpNm",
    "outputId": "3856dd0b-1891-490f-a95b-06754433d174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 204.54 ms, capturing 281 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 316.38 µs (0.15% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                   │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│    0.05% │\u001b[31m  105.38 µs │     1 │                                     │\u001b[1m cuModuleLoadDataEx      │\n",
       "│    0.04% │\u001b[33m   88.21 µs │    10 │   8.82 µs ± 12.46  (  3.81 ‥ 44.11) │\u001b[1m cuLaunchKernel          │\n",
       "│    0.02% │   46.49 µs │     1 │                                     │ cuModuleGetFunction     │\n",
       "│    0.01% │   11.21 µs │     1 │                                     │ cuCtxSynchronize        │\n",
       "│    0.00% │    5.48 µs │     1 │                                     │ cuMemAllocFromPoolAsync │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 57.94 µs (0.03% of the trace)\n",
       "┌──────────┬────────────┬───────┬────────────────────────────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                  │\u001b[1m Name                                                                                                                                                                                                                                                                                                       │\n",
       "├──────────┼────────────┼───────┼────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│    0.03% │\u001b[31m   57.94 µs │    10 │   5.79 µs ± 0.45   (  5.25 ‥ 6.91) │\u001b[1m gpu_copy_kernel_faster_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<1, Tuple<OneTo<Int64>>>, NDRange<1, DynamicSize, DynamicSize, CartesianIndices<1, Tuple<OneTo<Int64>>>, CartesianIndices<1, Tuple<OneTo<Int64>>>>>, CuDeviceArray<Float64, 1, 1>, CuDeviceArray<Float64, 1, 1>) │\n",
       "└──────────┴────────────┴───────┴────────────────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile let\n",
    "  d_A = similar(d_B)\n",
    "  for _ in 1:10\n",
    "    copy_kernel_faster!(CUDABackend())(d_A, d_B, ndrange=length(d_A))\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxXONwE_UYGF"
   },
   "source": [
    "## A more compilcated kernel -- transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdwzZOQ9VQWw",
    "outputId": "113e0401-d903-4a26-abc3-2966c99659c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const nreps = 3\n",
    "const N = 2048\n",
    "const T = Float32\n",
    "\n",
    "const TILE_DIM = 32\n",
    "const BLOCK_ROWS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O732YI3WWCnE"
   },
   "source": [
    "### Naive kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWDdbIl1UjYC",
    "outputId": "c5f150ab-e20f-4fd7-9b09-bf900ef14a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function simple_copy_kernel!(output, @Const(input))\n",
    "    I, J = @index(Global, NTuple)\n",
    "    @inbounds output[I, J] = input[I, J]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3sMLN2lT7s2",
    "outputId": "f4478256-b35e-473a-cbb1-4ef80cceadf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_transpose_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function simple_transpose_kernel!(output, @Const(input))\n",
    "    I, J = @index(Global, NTuple)\n",
    "    @inbounds output[J, I] = input[I, J]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbG1_3QPWFhN"
   },
   "source": [
    "### Using localmemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEBb8iCUUg2Q",
    "outputId": "321302ec-d358-47c8-f8fa-56956073a03f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lmem_copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel unsafe_indices = true function lmem_copy_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    I, J = @index(Global, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (N + BANK, M)\n",
    "\n",
    "    @inbounds tile[i, j] = input[I, J]\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    @inbounds output[I, J] = tile[i, j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHI9w-ggUE3y",
    "outputId": "075333c3-d4d3-4f0c-9fc0-90f5c9466a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lmem_transpose_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel unsafe_indices = true function lmem_transpose_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (N + BANK, M)\n",
    "\n",
    "    # Manually calculate global indexes\n",
    "    # Later on we need to pivot the group index\n",
    "    I = (gi - 1) * N + i\n",
    "    J = (gj - 1) * M + j\n",
    "\n",
    "    @inbounds tile[i, j] = input[I, J]\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    # Pivot the group index\n",
    "    I = (gj - 1) * M + i\n",
    "    J = (gi - 1) * N + j\n",
    "\n",
    "    @inbounds output[I, J] = tile[j, i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peMDm9SvVtrv"
   },
   "source": [
    "### Local Memory + process multiple elements per lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNhPHFEqU3Si"
   },
   "outputs": [],
   "source": [
    "using KernelAbstractions.Extras: @unroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inJxG14QVrKe",
    "outputId": "35a2b35c-52f5-4fd9-961c-43d45745b262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coalesced_copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel unsafe_indices=true function coalesced_copy_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # Can't use @index(Global), because we use a smaller ndrange\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds tile[i, j + k] = input[I, J + k]\n",
    "    end\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds output[I, J + k] = tile[i, j + k]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkybpxxlUS-2",
    "outputId": "fbc8dbad-31c3-4025-b945-68a46836de3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coalesced_transpose_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel unsafe_indices = true function coalesced_transpose_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # Can't use @index(Global), because we use a smaller ndrange\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds tile[i, j + k] = input[I, J + k]\n",
    "    end\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    # Transpose block offsets\n",
    "    I = (gj - 1) * TILE_DIM + i\n",
    "    J = (gi - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds output[I, J + k] = tile[j + k, i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq2pCjP4V6wf"
   },
   "source": [
    "### Benchmark harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsJ95M-OVKPv"
   },
   "outputs": [],
   "source": [
    "using NVTX, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lLdmw2nV-WT",
    "outputId": "d67c9e94-52e9-4d52-ef37-6618ea382991"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDABackend(false, false)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend = CUDABackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0A6CvDaVMnz",
    "outputId": "092aebc1-a8fc-4397-c308-25d2335f61d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 17.26 ms, capturing 5372 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 4.69 ms (27.17% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                     │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
       "│   71.43% │\u001b[31m   12.33 ms │     6 │   2.05 ms ± 1.29   (  0.64 ‥ 3.98)    │\u001b[1m cuStreamSynchronize     │\n",
       "│    1.05% │\u001b[33m  180.72 µs │    24 │   7.53 µs ± 3.92   (  4.29 ‥ 19.31)   │\u001b[1m cuLaunchKernel          │\n",
       "│    0.80% │  137.81 µs │     6 │  22.97 µs ± 5.96   ( 19.07 ‥ 34.81)   │ cudaLaunchKernel        │\n",
       "│    0.54% │   93.94 µs │    12 │   7.83 µs ± 3.72   (  3.58 ‥ 13.59)   │ cuMemAllocFromPoolAsync │\n",
       "│    0.04% │    7.39 µs │    12 │ 615.91 ns ± 448.45 (   0.0 ‥ 1192.09) │ cudaGetLastError        │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 16.16 ms (93.62% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                         │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   26.33% │\u001b[31m    4.54 ms │     4 │   1.14 ms ± 0.0    (  1.13 ‥ 1.14)   │\u001b[1m gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      │\n",
       "│   18.60% │\u001b[33m    3.21 ms │     4 │ 802.46 µs ± 3.33   (798.46 ‥ 805.85) │\u001b[1m gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)  │\n",
       "│   17.80% │    3.07 ms │     4 │ 768.01 µs ± 3.44   (765.56 ‥ 772.95) │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) │\n",
       "│   13.06% │    2.25 ms │     4 │ 563.26 µs ± 8.18   (555.04 ‥ 573.87) │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) │\n",
       "│    7.33% │    1.27 ms │     4 │ 316.26 µs ± 2.03   (313.52 ‥ 318.29) │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)       │\n",
       "│    6.78% │    1.17 ms │     4 │ 292.48 µs ± 0.49   (291.82 ‥ 293.02) │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      │\n",
       "│    3.72% │  641.58 µs │     6 │ 106.93 µs ± 0.85   ( 106.1 ‥ 108.24) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                               │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                            │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────┤\n",
       "│   27.75% │\u001b[31m    4.79 ms │     1 │\u001b[1m Main.Simple copy (1, 1024)      │\n",
       "│   20.21% │\u001b[33m    3.49 ms │     1 │\u001b[1m Main.Simple transpose (32, 32)  │\n",
       "│   19.07% │    3.29 ms │     1 │ Main.Simple transpose (1024, 1) │\n",
       "│   14.36% │    2.48 ms │     1 │ Main.Simple transpose (1, 1024) │\n",
       "│    8.90% │    1.54 ms │     1 │ Main.Simple copy (32, 32)       │\n",
       "│    7.99% │    1.38 ms │     1 │ Main.Simple copy (1024, 1)      │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────┘\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile for block_dims in ((TILE_DIM, TILE_DIM), (TILE_DIM * TILE_DIM, 1), (1, TILE_DIM * TILE_DIM))\n",
    "    for (name, kernel) in (\n",
    "            (\"copy\", simple_copy_kernel!(backend, block_dims)),\n",
    "            (\"transpose\", simple_transpose_kernel!(backend, block_dims)),\n",
    "        )\n",
    "        NVTX.@range \"Simple $name $block_dims\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, ndrange = size(output))\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, ndrange = size(output))\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwL2dy7XVd4Z",
    "outputId": "e5b82069-5491-43bd-b6d4-76bcc7c0db82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 7.2 ms, capturing 3582 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 1.67 ms (23.24% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                     │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
       "│   53.14% │\u001b[31m    3.83 ms │     4 │ 956.89 µs ± 477.44 (709.06 ‥ 1672.98) │\u001b[1m cuStreamSynchronize     │\n",
       "│    1.74% │\u001b[33m  125.65 µs │    16 │   7.85 µs ± 3.47   (  4.77 ‥ 15.5)    │\u001b[1m cuLaunchKernel          │\n",
       "│    1.36% │   97.75 µs │     4 │  24.44 µs ± 4.58   (  20.5 ‥ 30.76)   │ cudaLaunchKernel        │\n",
       "│    0.92% │   66.04 µs │     8 │   8.26 µs ± 4.12   (  3.58 ‥ 15.02)   │ cuMemAllocFromPoolAsync │\n",
       "│    0.07% │    5.25 µs │     8 │ 655.65 ns ± 594.34 (   0.0 ‥ 1430.51) │ cudaGetLastError        │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 6.45 ms (89.56% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                              │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   30.03% │\u001b[31m    2.16 ms │     4 │ 540.73 µs ± 1.99   (538.11 ‥ 542.4)  │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) │\n",
       "│   17.94% │\u001b[33m    1.29 ms │     4 │  323.0 µs ± 2.04   (321.15 ‥ 325.2)  │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) │\n",
       "│   17.86% │    1.29 ms │     4 │ 321.51 µs ± 0.81   (320.67 ‥ 322.58) │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
       "│   17.85% │    1.29 ms │     4 │ 321.39 µs ± 1.66   (319.48 ‥ 323.3)  │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
       "│    5.89% │  424.15 µs │     4 │ 106.04 µs ± 3.63   (100.61 ‥ 108.24) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                    │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                                        │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────────────┤\n",
       "│   33.08% │\u001b[31m    2.38 ms │     1 │\u001b[1m Main.Localmem transpose (32, 32) bank=false │\n",
       "│   21.79% │    1.57 ms │     1 │ Main.Localmem copy (32, 32) bank=true       │\n",
       "│   21.58% │    1.55 ms │     1 │ Main.Localmem copy (32, 32) bank=false      │\n",
       "│   21.42% │    1.54 ms │     1 │ Main.Localmem transpose (32, 32) bank=true  │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark localmem\n",
    "CUDA.@profile for (name, kernel) in (\n",
    "        (\"copy\", lmem_copy_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
    "        (\"transpose\", lmem_transpose_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
    "    )\n",
    "    for bank in (true, false)\n",
    "        NVTX.@range \"Localmem $name ($TILE_DIM, $TILE_DIM) bank=$bank\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXxdCZBVVfj1",
    "outputId": "001f2805-91ab-4c25-eadc-a87ed3cf07dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 4.65 ms, capturing 2934 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 1.1 ms (23.57% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────┤\n",
       "│   23.73% │\u001b[31m     1.1 ms │     4 │ 275.67 µs ± 545.62 (  2.62 ‥ 1094.1) │\u001b[1m cuStreamSynchronize     │\n",
       "│    4.08% │\u001b[33m  189.78 µs │    16 │  11.86 µs ± 5.74   (  5.01 ‥ 28.37)  │\u001b[1m cuLaunchKernel          │\n",
       "│    1.81% │   83.92 µs │     4 │  20.98 µs ± 8.79   ( 15.74 ‥ 34.09)  │ cudaLaunchKernel        │\n",
       "│    1.26% │   58.65 µs │     8 │   7.33 µs ± 4.05   (  3.34 ‥ 13.35)  │ cuMemAllocFromPoolAsync │\n",
       "│    0.09% │    4.29 µs │     8 │ 536.44 ns ± 397.93 (   0.0 ‥ 953.67) │ cudaGetLastError        │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 3.85 ms (82.79% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                                  │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   35.41% │\u001b[31m    1.65 ms │     4 │ 411.33 µs ± 0.3    (411.03 ‥ 411.75) │\u001b[1m gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) │\n",
       "│   14.25% │\u001b[33m  662.33 µs │     4 │ 165.58 µs ± 0.5    (164.99 ‥ 166.18) │\u001b[1m gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) │\n",
       "│   11.99% │  557.18 µs │     4 │  139.3 µs ± 2.53   (137.57 ‥ 143.05) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
       "│   11.95% │  555.28 µs │     4 │ 138.82 µs ± 2.05   (137.57 ‥ 141.86) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
       "│    9.19% │  426.77 µs │     4 │ 106.69 µs ± 2.59   ( 103.0 ‥ 108.48) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                        │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                                                           │\n",
       "├──────────┼────────────┼───────┼────────────────────────────────────────────────────────────────┤\n",
       "│   40.50% │\u001b[31m    1.88 ms │     1 │\u001b[1m Main.Localmem + multiple elements transpose (32, 8) bank=false │\n",
       "│   20.22% │  939.37 µs │     1 │ Main.Localmem + multiple elements copy (32, 8) bank=true       │\n",
       "│   18.81% │  874.04 µs │     1 │ Main.Localmem + multiple elements transpose (32, 8) bank=true  │\n",
       "│   16.71% │  776.29 µs │     1 │ Main.Localmem + multiple elements copy (32, 8) bank=false      │\n",
       "└──────────┴────────────┴───────┴────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark localmem + multiple elements per lane\n",
    "CUDA.@profile for (name, kernel) in (\n",
    "        (\"copy\", coalesced_copy_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
    "        (\"transpose\", coalesced_transpose_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
    "    )\n",
    "    for bank in (true, false)\n",
    "        NVTX.@range \"Localmem + multiple elements $name ($TILE_DIM, $BLOCK_ROWS) bank=$bank\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # We want a number of blocks equivalent to (TILE_DIM, TILE_DIM)\n",
    "            # but our blocks are (TILE_DIM, BLOCK_ROWS) so we need to remove\n",
    "            # a factor from the size of the array otherwise we get to many blocks\n",
    "            block_factor = div(TILE_DIM, BLOCK_ROWS)\n",
    "            ndrange = (N, div(N, block_factor))\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNekriU2bSRB"
   },
   "source": [
    "## Atomic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yV55CsqMW1e0",
    "outputId": "df8dc127-bd63-4cb2-87f2-857b005387a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function racy_kernel!(out, arr)\n",
    "\ti, j = @index(Global, NTuple)\n",
    "\tfor k in 1:size(out, 1)\n",
    "\t\tout[k, i] += arr[i, j]\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9j2kFZ1ceBj"
   },
   "outputs": [],
   "source": [
    "using ImageShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "1wLZB_bHbYiJ",
    "outputId": "40f3f1a8-6cb8-4b57-d29c-af7332a6a222"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALFJREFUaAW9wTEKwCAAwMAIebg/b6dOikOR3ElAAhKQgAQkIAEJSEACEpCABCQgAQlIQAKymOxM/pOABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyGJymwQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAG54GFn8JGABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyAWDMwlIQAISkIAEJCABCby1LAQS5D4/RAAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALFJREFUaAW9wTEKwCAAwMAIebg/b6dOikOR3ElAAhKQgAQkIAEJSEACEpCABCQgAQlIQAKymOxM/pOABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyGJymwQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAG54GFn8JGABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyAWDMwlIQAISkIAEJCABCby1LAQS5D4/RAAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "50×50 Matrix{ColorTypes.Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = zeros(Float32, (50, 50));\n",
    "img[10:20, 10:20] .= 1;\n",
    "img[35:45, 35:45] .= 2;\n",
    "simshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "Y8t0Q2QpbdkM",
    "outputId": "15354de3-18d7-4e7d-d04a-266968b297b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA95JREFUaAW9wWGN6zgYAMD58SFwKdgYiiEYHoYumC2Gw2AMxWBTWGM4RVGVXaXNvtNJngkHySvDe9kr3VOYILwwkPwXXdaRPXW7MEE4GFbDJvldd1PdVJvupzBBOLj6Qpd1myEb3rvpqFbFU/cUJggHzSpbZZvhTLdgUVUFRdZ1T2GCcDAkq4EuGZJzWZM12U1HQ7MLE4SDq81wRZP8pvupoOiewgThraRZFc3/EyYIB83qqhlWD7/JfqoW34UJwsGwqrJk2Ay/qxZF0xVFtQsThIPFsPmSbIYzVZd1d9mqq74LE4QXkmZIukVFlnXvFRQUm2JVPYUJwkFFMgxXQ8YwnGloaDZdVuzCBOEg64rdkCTde4uC5qnLvgsThJe+rIpVserONKsuKzaLu6cwQTgYEi4Ykma4Olc9NdVq0e3CBOHgqtp0m4e/taCiqnZhgnAwZEPRZMXDkDC8t+gaFotq0WXFh6cwQThImqRZPSRDwvBel2V01abrdmGCcPCQPA3Fxao70226p5vqKUwQDoZkuHpIrprfZT913O3CBOEg44qkIGE4191wx83mLtuFCcJBlyQPXdEUNBcPZ6rVzaaj2IUJwkHCA1dZMjTDcCYrVh8+VSwW34UJwkHCVffwZfFAwvDegqIpqoLqw6ddmCAcXCQPVxlDsWrOVHQsWNB8yHZhgnCQNEOXNBd8ubjo3isysqpriq5Z7MIE4YWLi4YiaYaiOdctGrKiWTW7MEE4GJqCpCmGpMrOZDR8WDU3VLswQThIrrgaSIqkK7r3imZVkXVVsbh7ChOEF5pVwcCQnPv0oWKx+rRqdmGC8MIFXx4SLpLk3KduscpWHcUuTBAOsoFsSPjHH0Vyrsq6rOkWVdbtwgThoLrYDKuB4cxd06yyZtV9FyYIB8PF5kvxN7KsaLoPBcVPYYJwaqD5Tdd0Wfapy7qm2IUJwkGSMGQPRVYkdO81NA3dDdlPYYJwUCQPF11GwXBusekWHVmz2IUJwsGQXG2Sv1VQUC26n8IE4aWO5KEpmmQ4U5BRUXRUxS5MEA6a7OHmH6uGIRnea7rs7maVdR8+7cIE4SAZsrsrvmwuujNZd1OtmiIruqcwQXjhIcmaq+ZqSLKH97oF1WJzt/guTBAOLgoSkiTp6M5kDYtVR9Z8FyYIB8nDH0OyGpKhOlM0xaZoFlW3CxOEg2QYkmEzDFn3XkW16FissmwXJggHw6prrlZZ1Z3JyGgWFKsPd09hgvBSx0VHs7jozt1lBV3Hoqp2YYJwMGRZt7niy7niU0NGtWh+ChOEFy6GL1cPJMlvmi7bVItVsQsT/AtUFlxm95a9ugAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA95JREFUaAW9wWGN6zgYAMD58SFwKdgYiiEYHoYumC2Gw2AMxWBTWGM4RVGVXaXNvtNJngkHySvDe9kr3VOYILwwkPwXXdaRPXW7MEE4GFbDJvldd1PdVJvupzBBOLj6Qpd1myEb3rvpqFbFU/cUJggHzSpbZZvhTLdgUVUFRdZ1T2GCcDAkq4EuGZJzWZM12U1HQ7MLE4SDq81wRZP8pvupoOiewgThraRZFc3/EyYIB83qqhlWD7/JfqoW34UJwsGwqrJk2Ay/qxZF0xVFtQsThIPFsPmSbIYzVZd1d9mqq74LE4QXkmZIukVFlnXvFRQUm2JVPYUJwkFFMgxXQ8YwnGloaDZdVuzCBOEg64rdkCTde4uC5qnLvgsThJe+rIpVserONKsuKzaLu6cwQTgYEi4Ykma4Olc9NdVq0e3CBOHgqtp0m4e/taCiqnZhgnAwZEPRZMXDkDC8t+gaFotq0WXFh6cwQThImqRZPSRDwvBel2V01abrdmGCcPCQPA3Fxao70226p5vqKUwQDoZkuHpIrprfZT913O3CBOEg44qkIGE4191wx83mLtuFCcJBlyQPXdEUNBcPZ6rVzaaj2IUJwkHCA1dZMjTDcCYrVh8+VSwW34UJwkHCVffwZfFAwvDegqIpqoLqw6ddmCAcXCQPVxlDsWrOVHQsWNB8yHZhgnCQNEOXNBd8ubjo3isysqpriq5Z7MIE4YWLi4YiaYaiOdctGrKiWTW7MEE4GJqCpCmGpMrOZDR8WDU3VLswQThIrrgaSIqkK7r3imZVkXVVsbh7ChOEF5pVwcCQnPv0oWKx+rRqdmGC8MIFXx4SLpLk3KduscpWHcUuTBAOsoFsSPjHH0Vyrsq6rOkWVdbtwgThoLrYDKuB4cxd06yyZtV9FyYIB8PF5kvxN7KsaLoPBcVPYYJwaqD5Tdd0Wfapy7qm2IUJwkGSMGQPRVYkdO81NA3dDdlPYYJwUCQPF11GwXBusekWHVmz2IUJwsGQXG2Sv1VQUC26n8IE4aWO5KEpmmQ4U5BRUXRUxS5MEA6a7OHmH6uGIRnea7rs7maVdR8+7cIE4SAZsrsrvmwuujNZd1OtmiIruqcwQXjhIcmaq+ZqSLKH97oF1WJzt/guTBAOLgoSkiTp6M5kDYtVR9Z8FyYIB8nDH0OyGpKhOlM0xaZoFlW3CxOEg2QYkmEzDFn3XkW16FissmwXJggHw6prrlZZ1Z3JyGgWFKsPd09hgvBSx0VHs7jozt1lBV3Hoqp2YYJwMGRZt7niy7niU0NGtWh+ChOEFy6GL1cPJMlvmi7bVItVsQsT/AtUFlxm95a9ugAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "50×50 Matrix{ColorTypes.Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.142857  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.142857  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.142857  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.428571  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0       0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.714286  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.571429  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.142857  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.285714  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.428571  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.857143  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.428571  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.428571  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.571429  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = KernelAbstractions.zeros(backend, Float32, size(img));\n",
    "racy_kernel!(backend)(out, adapt(backend, img), ndrange=size(img))\n",
    "simshow(Array(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V02D9krWbvAN"
   },
   "outputs": [],
   "source": [
    "using Atomix: @atomic, @atomicswap, @atomicreplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD0eol-2cx41",
    "outputId": "d77fe6bc-4778-4c47-82a5-51f57232edb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nonracy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function nonracy_kernel!(out, arr)\n",
    "\ti, j = @index(Global, NTuple)\n",
    "\tfor k in 1:size(out, 1)\n",
    "\t\t@atomic out[k, i] += arr[i, j]\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "Sa-Gzr7tc61f",
    "outputId": "4adde915-9d32-44d2-829a-dd14162e1540"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKpJREFUaAW9wTESABAAwLC668P9nMmEtYlcJi+Tv8XL4JCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCSwAdRJA5GDmgLcAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKpJREFUaAW9wTESABAAwLC668P9nMmEtYlcJi+Tv8XL4JCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCSwAdRJA5GDmgLcAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "50×50 Matrix{ColorTypes.Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = KernelAbstractions.zeros(backend, Float32, size(img));\n",
    "nonracy_kernel!(backend)(out, adapt(backend, img), ndrange=size(img))\n",
    "simshow(Array(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoCwrdAKd1Ut"
   },
   "source": [
    "## Matrix multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJ7ErQTfd4ZO",
    "outputId": "263e9c3b-580a-4edc-a661-cce2c4ca3fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "naive_matmul! (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function naive_matmul_kernel!(output, a, b)\n",
    "    i, j = @index(Global, NTuple)\n",
    "\n",
    "    # creating a temporary sum variable for matrix multiplication\n",
    "    tmp_sum = zero(eltype(output))\n",
    "    for k in 1:size(a)[2]\n",
    "        tmp_sum += a[i, k] * b[k, j]\n",
    "    end\n",
    "\n",
    "    output[i, j] = tmp_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-miQrox1ebjt"
   },
   "outputs": [],
   "source": [
    "# Creating a wrapper kernel for launching with error checks\n",
    "function naive_matmul!(output, a, b)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"Matrix size mismatch!\")\n",
    "        return nothing\n",
    "    end\n",
    "    backend = KernelAbstractions.get_backend(a)\n",
    "    kernel! = naive_matmul_kernel!(backend)\n",
    "    kernel!(output, a, b, ndrange = size(output))\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc4MplI9d89w"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  a = rand!(allocate(backend, Float32, 256, 123))\n",
    "  b = rand!(allocate(backend, Float32, 123, 45))\n",
    "  output = KernelAbstractions.zeros(backend, Float32, 256, 45)\n",
    "\n",
    "  naive_matmul!(output, a, b)\n",
    "\n",
    "  @assert isapprox(output, a * b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mN1LbGM7eGZL"
   },
   "outputs": [],
   "source": [
    "@kernel unsafe_indices = true function coalesced_matmul_kernel!(\n",
    "        output, @Const(A), @Const(B),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile1 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "    tile2 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # private variable for tile output\n",
    "    outval = @private eltype(output) 1\n",
    "    @inbounds outval[1] = -zero(eltype(output))\n",
    "\n",
    "    @uniform N = size(output, 1)\n",
    "    @uniform M = size(output, 2)\n",
    "    @uniform R = size(A, 2)\n",
    "    # number of tiles depends on inner dimension\n",
    "    @uniform NUM_TILES = div(R + TILE_DIM - 1, TILE_DIM)\n",
    "\n",
    "    # loop over all tiles needed for this calculation\n",
    "    for t in 0:(NUM_TILES - 1)\n",
    "        # Can't use @index(Global), because we use a smaller ndrange\n",
    "        I = (gi - 1) * TILE_DIM + i\n",
    "        J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "        # load inputs into tiles, with bounds checking for non-square matrices\n",
    "        if I <= N && t * TILE_DIM + j <= R\n",
    "            @inbounds tile1[i, j] = A[I, t * TILE_DIM + j]\n",
    "        else\n",
    "            @inbounds tile1[i, j] = 0.0\n",
    "        end\n",
    "        if t * TILE_DIM + i <= R && J <= M\n",
    "            @inbounds tile2[i, j] = B[t * TILE_DIM + i, J]\n",
    "        else\n",
    "            @inbounds tile2[i, j] = 0.0\n",
    "        end\n",
    "\n",
    "        # wait for all tiles to be loaded\n",
    "        @synchronize\n",
    "\n",
    "        # get global values again\n",
    "        I = (gi - 1) * TILE_DIM + i\n",
    "        J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "        # calculate value of spot in output, use temporary value to allow for vectorization\n",
    "        out = zero(eltype(output))\n",
    "        @simd for k in 1:TILE_DIM\n",
    "            @inbounds out += tile1[i, k] * tile2[k, j]\n",
    "        end\n",
    "        outval[1] += out\n",
    "\n",
    "        @synchronize\n",
    "    end\n",
    "\n",
    "    # get global indices again\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    # save if inbounds\n",
    "    if I <= N && J <= M\n",
    "        @inbounds output[I, J] = outval[1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dE4LNL5Zecj3",
    "outputId": "89ad6250-24b3-4d13-fde9-95731853b1de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coalesced_matmul! (generic function with 1 method)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a wrapper kernel for launching with error checks\n",
    "function coalesced_matmul!(output, a, b)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"Matrix size mismatch!\")\n",
    "        return nothing\n",
    "    end\n",
    "    backend = KernelAbstractions.get_backend(a)\n",
    "    kernel! = coalesced_matmul_kernel!(backend, (TILE_DIM, TILE_DIM))\n",
    "    kernel!(output, a, b, ndrange = size(output))\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM9J-KMnetKN"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  a = rand!(allocate(backend, Float32, 256, 123))\n",
    "  b = rand!(allocate(backend, Float32, 123, 45))\n",
    "  output = KernelAbstractions.zeros(backend, Float32, 256, 45)\n",
    "\n",
    "  coalesced_matmul!(output, a, b)\n",
    "\n",
    "  @assert isapprox(output, a * b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3ZPZNcmfv3b"
   },
   "outputs": [],
   "source": [
    "import LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw9Uuzn0hM0I"
   },
   "source": [
    "### Exercise\n",
    "- Vary N, R, M\n",
    "- Vary T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOwz86oLfYjs",
    "outputId": "fa4beb7d-9c82-4411-8fe9-5e12e37f6e8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 211.92 ms, capturing 7394 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 67.39 ms (31.80% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────┤\n",
       "│   97.21% │\u001b[31m  206.02 ms │     9 │  22.89 ms ± 2.26   (  20.4 ‥ 26.56)  │\u001b[1m cuStreamSynchronize     │\n",
       "│    0.08% │\u001b[33m  162.36 µs │     6 │  27.06 µs ± 4.18   ( 20.98 ‥ 31.23)  │\u001b[1m cuLaunchKernel          │\n",
       "│    0.03% │   70.33 µs │     6 │  11.72 µs ± 6.26   (  4.29 ‥ 18.12)  │ cuMemAllocFromPoolAsync │\n",
       "│    0.03% │   62.23 µs │     6 │  10.37 µs ± 7.08   (  3.58 ‥ 18.36)  │ cuMemcpyHtoDAsync       │\n",
       "│    0.02% │   52.21 µs │     3 │   17.4 µs ± 0.63   ( 16.93 ‥ 18.12)  │ cudaLaunchKernel        │\n",
       "│    0.00% │    1.91 µs │     3 │ 635.78 ns ± 275.3  (476.84 ‥ 953.67) │ cudaGetLastError        │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 210.23 ms (99.20% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                                                                                                                │\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   34.03% │\u001b[31m   72.11 ms │     3 │  24.04 ms ± 2.59   ( 22.53 ‥ 27.03)  │\u001b[1m gpu_coalesced_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float64, 2, 1>, Float64, Float64)                                                                                │\n",
       "│   33.54% │   71.07 ms │     3 │  23.69 ms ± 2.26   ( 21.12 ‥ 25.37)  │ gpu_naive_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, DynamicSize, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>>>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>) │\n",
       "│   31.63% │   67.04 ms │     3 │  22.35 ms ± 2.49   ( 20.91 ‥ 25.22)  │ volta_dgemm_128x64_nn                                                                                                                                                                                                                                                                                                                                                               │\n",
       "│    0.00% │    4.53 µs │     6 │ 754.99 ns ± 179.47 (476.84 ‥ 953.67) │ [copy pageable to device memory]                                                                                                                                                                                                                                                                                                                                                    │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                   │\u001b[1m Name                    │\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   34.23% │\u001b[31m   72.54 ms │     3 │  24.18 ms ± 2.6    ( 22.66 ‥ 27.18) │\u001b[1m Main.Coalesced Matmul   │\n",
       "│   33.77% │   71.56 ms │     3 │  23.85 ms ± 2.29   ( 21.26 ‥ 25.57) │ Main.Naive Matmul       │\n",
       "│   31.98% │   67.78 ms │     3 │  22.59 ms ± 2.51   ( 21.14 ‥ 25.49) │ Main.LinearAlgebra.mul! │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    N = 1024\n",
    "    R = 512\n",
    "    M = 2048\n",
    "    T = Float64\n",
    "    A = rand!(allocate(backend, T, N, R))\n",
    "    B = rand!(allocate(backend, T, R, M))\n",
    "    output_naive = KernelAbstractions.zeros(backend, T, N, M)\n",
    "    output_coalesced = KernelAbstractions.zeros(backend, T, N, M)\n",
    "    output_mul = KernelAbstractions.zeros(backend, T, N, M)\n",
    "\n",
    "\n",
    "    CUDA.@profile for _ in 1:nreps\n",
    "      NVTX.@range \"Naive Matmul\" begin\n",
    "          naive_matmul!(output_naive, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "\n",
    "      NVTX.@range \"Coalesced Matmul\" begin\n",
    "          coalesced_matmul!(output_coalesced, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "\n",
    "      NVTX.@range \"LinearAlgebra.mul!\" begin\n",
    "          LinearAlgebra.mul!(output_mul, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Julia",
   "name": "julia"
  },
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
