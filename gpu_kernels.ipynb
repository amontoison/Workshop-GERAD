{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLxjjaJb8iW_"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amontoison/Workshop-GERAD/blob/main/gpu_kernels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjJTIwxxJjwX"
      },
      "source": [
        "# Parallel computing and GPU programming with Julia\n",
        "## Part IV: GPU Kernels with KernelAbstractions.jl\n",
        "Alexis Montoison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSgoDg8fFyEp",
        "outputId": "e2fd3e3d-d1e7-47d3-f130-a19a761ac67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/content/colab6`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/content/colab6/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/content/colab6/Manifest.toml`\n"
          ]
        }
      ],
      "source": [
        "import Pkg\n",
        "Pkg.activate(\"colab6\")\n",
        "Pkg.add([\"CUDA\", \"KernelAbstractions\", \"Adapt\", \"NVTX\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJdnRZwNF2fh",
        "outputId": "c2955317-95ee-4459-d411-3b2ee9790649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.11.5\n",
            "Commit 760b2e5b739 (2025-04-14 06:53 UTC)\n",
            "Build Info:\n",
            "  Official https://julialang.org/ release\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-linux-gnu)\n",
            "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LLVM: libLLVM-16.0.6 (ORCJIT, broadwell)\n",
            "Threads: 2 default, 0 interactive, 1 GC (on 2 virtual cores)\n",
            "Environment:\n",
            "  LD_LIBRARY_PATH = /usr/lib64-nvidia\n",
            "  JULIA_NUM_THREADS = auto\n"
          ]
        }
      ],
      "source": [
        "versioninfo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Ru_R_unVF8JR"
      },
      "outputs": [],
      "source": [
        "using CUDA, KernelAbstractions, Adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJThsWC1Jjwk"
      },
      "source": [
        "### Different layers of abstraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCfnoeRH8iXN",
        "outputId": "8f71ce4d-dd4d-41a8-c524-bc4ca11cc54e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000-element CuArray{Float64, 1, CUDA.DeviceMemory}:\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " ⋮\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0\n",
              " 0.0"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "N = 100000\n",
        "a = 0.5\n",
        "X_cpu = rand(Float64, N)\n",
        "Y_cpu = zeros(Float64, N)\n",
        "X = CuVector(X_cpu)\n",
        "Y = CuVector(Y_cpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fURgDPvJjwl"
      },
      "source": [
        "#### Vendor-specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "s8i8b3ZtJjwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9409b412-69ad-4a65-f30d-ab2065fd0f22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000-element CuArray{Float64, 1, CUDA.DeviceMemory}:\n",
              " 0.33045790611431836\n",
              " 0.43026941175472044\n",
              " 0.2655251196768881\n",
              " 0.30431028823100975\n",
              " 0.4984157599454933\n",
              " 0.06844620328876744\n",
              " 0.04356821751944773\n",
              " 0.3039996204893953\n",
              " 0.3470413837393167\n",
              " 0.21084902980004128\n",
              " 0.49739871546275766\n",
              " 0.26946405756976854\n",
              " 0.39399730811097383\n",
              " ⋮\n",
              " 0.34720675347596064\n",
              " 0.4102826154053107\n",
              " 0.06637767845128689\n",
              " 0.06131294496972045\n",
              " 0.17867465569849922\n",
              " 0.07179257783763593\n",
              " 0.25818125925969654\n",
              " 0.28494254924418655\n",
              " 0.48525902498096957\n",
              " 0.3075968283124345\n",
              " 0.45602960422026084\n",
              " 0.2026006329768757"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "function saxpy!(a,X,Y)\n",
        "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
        "    if i <= length(Y)\n",
        "        @inbounds Y[i] = a * X[i] + Y[i]\n",
        "    end\n",
        "    return nothing\n",
        "end\n",
        "\n",
        "@cuda threads=32 blocks=cld(length(Y), 32) saxpy!(a, X, Y)\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlA94N55Jjwn"
      },
      "source": [
        "#### KernelAbstractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "uLaCJWFYJjwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5724c92-4507-4767-90f1-2d08d2dd7cc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000-element CuArray{Float64, 1, CUDA.DeviceMemory}:\n",
              " 0.6609158122286367\n",
              " 0.8605388235094409\n",
              " 0.5310502393537762\n",
              " 0.6086205764620195\n",
              " 0.9968315198909866\n",
              " 0.13689240657753488\n",
              " 0.08713643503889545\n",
              " 0.6079992409787905\n",
              " 0.6940827674786334\n",
              " 0.42169805960008255\n",
              " 0.9947974309255153\n",
              " 0.5389281151395371\n",
              " 0.7879946162219477\n",
              " ⋮\n",
              " 0.6944135069519213\n",
              " 0.8205652308106214\n",
              " 0.13275535690257378\n",
              " 0.1226258899394409\n",
              " 0.35734931139699844\n",
              " 0.14358515567527186\n",
              " 0.5163625185193931\n",
              " 0.5698850984883731\n",
              " 0.9705180499619391\n",
              " 0.615193656624869\n",
              " 0.9120592084405217\n",
              " 0.4052012659537514"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "using KernelAbstractions\n",
        "using CUDA\n",
        "\n",
        "@kernel function kernel_saxpy!(a, @Const(X), Y)\n",
        "    I = @index(Global)\n",
        "    @inbounds Y[I] = a * X[I] + Y[I]\n",
        "end\n",
        "\n",
        "kernel_saxpy!(CUDABackend())(a, X, Y, ndrange=length(Y))\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Co2nDQkJjwr"
      },
      "source": [
        "#### Array abstractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "-MD_tILRJjwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3acaeb-5ee5-4b9a-ee9e-6a40518f109c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000-element CuArray{Float64, 1, CUDA.DeviceMemory}:\n",
              " 0.9913737183429551\n",
              " 1.2908082352641612\n",
              " 0.7965753590306642\n",
              " 0.9129308646930292\n",
              " 1.49524727983648\n",
              " 0.2053386098663023\n",
              " 0.13070465255834318\n",
              " 0.9119988614681858\n",
              " 1.04112415121795\n",
              " 0.6325470894001238\n",
              " 1.492196146388273\n",
              " 0.8083921727093056\n",
              " 1.1819919243329216\n",
              " ⋮\n",
              " 1.041620260427882\n",
              " 1.230847846215932\n",
              " 0.19913303535386068\n",
              " 0.18393883490916135\n",
              " 0.5360239670954976\n",
              " 0.2153777335129078\n",
              " 0.7745437777790896\n",
              " 0.8548276477325596\n",
              " 1.4557770749429086\n",
              " 0.9227904849373035\n",
              " 1.3680888126607824\n",
              " 0.6078018989306271"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "Y .= a .* X .+ Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exMYwQUT8iXU"
      },
      "source": [
        "### KernelAbstractions.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVDdv25q8iXU"
      },
      "source": [
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA1.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA2.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA3.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA4.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA5.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA6.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA7.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA8.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA9.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA10.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA11.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA12.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA13.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA14.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA15.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA16.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA17.png?raw=1' width='1000px'>\n",
        "<img src='https://github.com/amontoison/Workshop-GERAD/blob/main/Graphics/KA18.png?raw=1' width='1000px'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ZB0lDaJjwt"
      },
      "source": [
        "#### Summary -- How to use KernelAbstractions?\n",
        "\n",
        "- Use `@kernel function mykernel(args...) end` to write a GPU-style program\n",
        "- Instantiate kernel for a backend `kernel = mykernel(backend)`\n",
        "- Backends come from Vendor specific libraries\n",
        "- `KA.allocate(backend, ...)` to obtain memory\n",
        "- Launch kernel `kernel(args..., ndrange=...)` while specifying the grid to execute over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "lCjiqBQQJjwv"
      },
      "outputs": [],
      "source": [
        "function vadd(a, b, c)\n",
        "    for i in eachindex(c)\n",
        "        c[i] = a[i] + b[i]\n",
        "    end\n",
        "end\n",
        "\n",
        "a = rand(N)\n",
        "b = rand(N)\n",
        "c = similar(a)\n",
        "\n",
        "vadd(a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "Zxhl2gcyJjwv"
      },
      "outputs": [],
      "source": [
        "import KernelAbstractions as KA\n",
        "\n",
        "@kernel function vadd_kernel(a, b, c)\n",
        "    i = @index(Global)\n",
        "    c[i] = a[i] + b[i]\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend = CUDABackend()\n",
        "a = KA.allocate(backend, Float32, N)\n",
        "b = KA.allocate(backend, Float32, N)\n",
        "c = similar(a)\n",
        "\n",
        "vadd_kernel(backend)(a, b, c; ndrange=size(c))"
      ],
      "metadata": {
        "id": "f9QGdbIw96fm"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcXK1M6TJjwv"
      },
      "source": [
        "#### Asynchronous operations\n",
        "\n",
        "GPU operations are asynchronous with regards to the host! They are **ordered** with respect to each other, but special care must be taken when using Julia's task based programming together with GPU programming.\n",
        "\n",
        "The JuliaGPU ecosystem **synchronizes** the GPU on access, so when you move data from and to the GPU we wait for all the kernels to finish!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfgVGjrJjww"
      },
      "source": [
        "When benchmarking you need to synchronize the device!\n",
        "\n",
        "```julia\n",
        "@benchmark begin\n",
        "    vadd_kernel(a, b, c; ndrange=size(c))\n",
        "    KA.synchronize(backend)\n",
        "end\n",
        "```\n",
        "\n",
        "Otherwise you are only measuring the **launch** of the kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LW51Tc5Jjwz"
      },
      "source": [
        "### What makes an application portable?\n",
        "\n",
        "1. Can I **run** it on a different compute architecture\n",
        "    1. Different CPU architectures\n",
        "    2. We live in a mult GPU vendor world\n",
        "2. Does it **compute** the same thing?\n",
        "    1. Can I develop on one platform and move to another later?\n",
        "3. Does it achieve the same **performance**?\n",
        "4. Can I take advantage of platform **specific** capabilities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEawmex5Jjw0"
      },
      "source": [
        "#### Adapt.jl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsLBPf2nJjw0"
      },
      "source": [
        "[Adapt.jl](https://github.com/JuliaGPU/Adapt.jl) is a lightweight dependency that you can use to convert complex structures from CPU to GPU.\n",
        "\n",
        "```julia\n",
        "using Adapt\n",
        "adapt(CuArray, ::Adjoint{Array})::Adjoint{CuArray}\n",
        "```\n",
        "\n",
        "```julia\n",
        "struct Model{T<:Number, AT<:AbstractArray{T}}\n",
        "   data::AT\n",
        "end\n",
        "\n",
        "Adapt.adapt_structure(to, x::Model) = Model(adapt(to, x.data))\n",
        "\n",
        "cpu = Model(rand(64, 64));\n",
        "using CUDA\n",
        "\n",
        "gpu = adapt(CuArray, cpu)\n",
        "Model{Float64, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}}(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXONwE_UYGF"
      },
      "source": [
        "## GPU kernel -- transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdwzZOQ9VQWw",
        "outputId": "c0b2029d-ee37-4529-e5be-9b96d1bb30fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "nreps = 3\n",
        "N = 2048\n",
        "T = Float32\n",
        "\n",
        "TILE_DIM = 32\n",
        "BLOCK_ROWS = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O732YI3WWCnE"
      },
      "source": [
        "### Naive kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "RWDdbIl1UjYC"
      },
      "outputs": [],
      "source": [
        "@kernel function simple_copy_kernel!(output, @Const(input))\n",
        "    I, J = @index(Global, NTuple)\n",
        "    @inbounds output[I, J] = input[I, J]\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "k3sMLN2lT7s2"
      },
      "outputs": [],
      "source": [
        "@kernel function simple_transpose_kernel!(output, @Const(input))\n",
        "    I, J = @index(Global, NTuple)\n",
        "    @inbounds output[J, I] = input[I, J]\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbG1_3QPWFhN"
      },
      "source": [
        "### Using localmemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "KEBb8iCUUg2Q"
      },
      "outputs": [],
      "source": [
        "@kernel unsafe_indices = true function lmem_copy_kernel!(\n",
        "        output, @Const(input),\n",
        "        ::Val{BANK} = Val(1),\n",
        "    ) where {BANK}\n",
        "    I, J = @index(Global, NTuple)\n",
        "    i, j = @index(Local, NTuple)\n",
        "\n",
        "    N = @uniform @groupsize()[1]\n",
        "    M = @uniform @groupsize()[2]\n",
        "\n",
        "    # +1 to avoid bank conflicts on shared memory\n",
        "    tile = @localmem eltype(output) (N + BANK, M)\n",
        "\n",
        "    @inbounds tile[i, j] = input[I, J]\n",
        "\n",
        "    @synchronize\n",
        "\n",
        "    @inbounds output[I, J] = tile[i, j]\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ZHI9w-ggUE3y"
      },
      "outputs": [],
      "source": [
        "@kernel unsafe_indices = true function lmem_transpose_kernel!(\n",
        "        output, @Const(input),\n",
        "        ::Val{BANK} = Val(1),\n",
        "    ) where {BANK}\n",
        "    gi, gj = @index(Group, NTuple)\n",
        "    i, j = @index(Local, NTuple)\n",
        "\n",
        "    N = @uniform @groupsize()[1]\n",
        "    M = @uniform @groupsize()[2]\n",
        "\n",
        "    # +1 to avoid bank conflicts on shared memory\n",
        "    tile = @localmem eltype(output) (N + BANK, M)\n",
        "\n",
        "    # Manually calculate global indexes\n",
        "    # Later on we need to pivot the group index\n",
        "    I = (gi - 1) * N + i\n",
        "    J = (gj - 1) * M + j\n",
        "\n",
        "    @inbounds tile[i, j] = input[I, J]\n",
        "\n",
        "    @synchronize\n",
        "\n",
        "    # Pivot the group index\n",
        "    I = (gj - 1) * M + i\n",
        "    J = (gi - 1) * N + j\n",
        "\n",
        "    @inbounds output[I, J] = tile[j, i]\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peMDm9SvVtrv"
      },
      "source": [
        "### Local Memory + process multiple elements per lane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "JNhPHFEqU3Si"
      },
      "outputs": [],
      "source": [
        "using KernelAbstractions.Extras: @unroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "inJxG14QVrKe"
      },
      "outputs": [],
      "source": [
        "@kernel unsafe_indices=true function coalesced_copy_kernel!(\n",
        "        output, @Const(input),\n",
        "        ::Val{BANK} = Val(1),\n",
        "    ) where {BANK}\n",
        "    gi, gj = @index(Group, NTuple)\n",
        "    i, j = @index(Local, NTuple)\n",
        "\n",
        "    TILE_DIM = @uniform @groupsize()[1]\n",
        "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
        "\n",
        "    # +1 to avoid bank conflicts on shared memory\n",
        "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
        "\n",
        "    # Can't use @index(Global), because we use a smaller ndrange\n",
        "    I = (gi - 1) * TILE_DIM + i\n",
        "    J = (gj - 1) * TILE_DIM + j\n",
        "\n",
        "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
        "        @inbounds tile[i, j + k] = input[I, J + k]\n",
        "    end\n",
        "\n",
        "    @synchronize\n",
        "\n",
        "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
        "        @inbounds output[I, J + k] = tile[i, j + k]\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "XkybpxxlUS-2"
      },
      "outputs": [],
      "source": [
        "@kernel unsafe_indices = true function coalesced_transpose_kernel!(\n",
        "        output, @Const(input),\n",
        "        ::Val{BANK} = Val(1),\n",
        "    ) where {BANK}\n",
        "    gi, gj = @index(Group, NTuple)\n",
        "    i, j = @index(Local, NTuple)\n",
        "\n",
        "    TILE_DIM = @uniform @groupsize()[1]\n",
        "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
        "\n",
        "    # +1 to avoid bank conflicts on shared memory\n",
        "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
        "\n",
        "    # Can't use @index(Global), because we use a smaller ndrange\n",
        "    I = (gi - 1) * TILE_DIM + i\n",
        "    J = (gj - 1) * TILE_DIM + j\n",
        "\n",
        "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
        "        @inbounds tile[i, j + k] = input[I, J + k]\n",
        "    end\n",
        "\n",
        "    @synchronize\n",
        "\n",
        "    # Transpose block offsets\n",
        "    I = (gj - 1) * TILE_DIM + i\n",
        "    J = (gi - 1) * TILE_DIM + j\n",
        "\n",
        "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
        "        @inbounds output[I, J + k] = tile[j + k, i]\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq2pCjP4V6wf"
      },
      "source": [
        "### Benchmark harness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "AsJ95M-OVKPv"
      },
      "outputs": [],
      "source": [
        "using NVTX, Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lLdmw2nV-WT",
        "outputId": "ec006bf8-2b9a-4191-eecb-b0c492a304df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUDABackend(false, false)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "backend = CUDABackend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0A6CvDaVMnz",
        "outputId": "2ae69ddc-8893-4814-bd43-e05704d6df83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Profiler ran for 453.64 ms, capturing 5492 events.\n",
              "\n",
              "Host-side activity: calling CUDA APIs took 4.74 ms (1.04% of the trace)\n",
              "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                   │\u001b[1m Name                    │\n",
              "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
              "│    2.64% │\u001b[31m   11.96 ms │     6 │   1.99 ms ± 1.39   (  0.29 ‥ 4.05)  │\u001b[1m cuStreamSynchronize     │\n",
              "│    0.11% │\u001b[33m  476.84 µs │     6 │  79.47 µs ± 11.75  ( 61.51 ‥ 92.74) │\u001b[1m cuModuleLoadDataEx      │\n",
              "│    0.07% │  309.71 µs │    24 │   12.9 µs ± 10.49  (  4.29 ‥ 39.1)  │ cuLaunchKernel          │\n",
              "│    0.06% │  264.64 µs │     6 │  44.11 µs ± 4.02   ( 36.95 ‥ 47.45) │ cuModuleGetFunction     │\n",
              "│    0.04% │  164.03 µs │     6 │  27.34 µs ± 4.36   ( 22.17 ‥ 32.66) │ cudaLaunchKernel        │\n",
              "│    0.03% │   147.1 µs │    12 │  12.26 µs ± 7.83   (  3.34 ‥ 22.41) │ cuMemAllocFromPoolAsync │\n",
              "│    0.02% │   79.63 µs │     6 │  13.27 µs ± 1.27   ( 10.97 ‥ 14.78) │ cuCtxSynchronize        │\n",
              "│    0.00% │   12.16 µs │    12 │   1.01 µs ± 0.95   (   0.0 ‥ 2.15)  │ cudaGetLastError        │\n",
              "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
              "\n",
              "Device-side activity: GPU was busy for 16.74 ms (3.69% of the trace)\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                         │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│    1.01% │\u001b[31m    4.57 ms │     4 │   1.14 ms ± 0.0    (  1.14 ‥ 1.14)   │\u001b[1m gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      │\n",
              "│    0.72% │\u001b[33m    3.25 ms │     4 │ 812.77 µs ± 2.25   (809.91 ‥ 814.68) │\u001b[1m gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)  │\n",
              "│    0.68% │     3.1 ms │     4 │ 774.86 µs ± 3.13   (771.76 ‥ 778.91) │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) │\n",
              "│    0.50% │    2.28 ms │     4 │ 569.34 µs ± 6.19   (562.19 ‥ 576.97) │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) │\n",
              "│    0.27% │    1.25 ms │     4 │ 311.73 µs ± 1.06   ( 310.9 ‥ 313.28) │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)       │\n",
              "│    0.25% │    1.15 ms │     6 │ 191.53 µs ± 9.05   (180.72 ‥ 204.09) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                               │\n",
              "│    0.25% │    1.14 ms │     4 │ 286.22 µs ± 1.11   (285.15 ‥ 287.29) │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
              "\n",
              "NVTX ranges:\n",
              "┌──────────┬────────────┬───────┬─────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                            │\n",
              "├──────────┼────────────┼───────┼─────────────────────────────────┤\n",
              "│   18.47% │\u001b[31m   83.79 ms │     1 │\u001b[1m Main.Simple transpose (1024, 1) │\n",
              "│   16.59% │\u001b[33m   75.27 ms │     1 │\u001b[1m Main.Simple transpose (32, 32)  │\n",
              "│   16.43% │   74.55 ms │     1 │ Main.Simple copy (1, 1024)      │\n",
              "│   16.22% │   73.59 ms │     1 │ Main.Simple copy (32, 32)       │\n",
              "│   16.18% │   73.41 ms │     1 │ Main.Simple copy (1024, 1)      │\n",
              "│   16.04% │   72.78 ms │     1 │ Main.Simple transpose (1, 1024) │\n",
              "└──────────┴────────────┴───────┴─────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "CUDA.@profile for block_dims in ((TILE_DIM, TILE_DIM), (TILE_DIM * TILE_DIM, 1), (1, TILE_DIM * TILE_DIM))\n",
        "    for (name, kernel) in (\n",
        "            (\"copy\", simple_copy_kernel!(backend, block_dims)),\n",
        "            (\"transpose\", simple_transpose_kernel!(backend, block_dims)),\n",
        "        )\n",
        "        NVTX.@range \"Simple $name $block_dims\" let\n",
        "            input = rand!(allocate(backend, T, N, N))\n",
        "            output = similar(input)\n",
        "\n",
        "            # compile kernel\n",
        "            kernel(output, input, ndrange = size(output))\n",
        "            for rep in 1:nreps\n",
        "                kernel(output, input, ndrange = size(output))\n",
        "            end\n",
        "            KernelAbstractions.synchronize(backend)\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwL2dy7XVd4Z",
        "outputId": "2b8599a1-6887-44b6-8e2b-455ed50713b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Profiler ran for 444.98 ms, capturing 3662 events.\n",
              "\n",
              "Host-side activity: calling CUDA APIs took 2.22 ms (0.50% of the trace)\n",
              "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                     │\u001b[1m Name                    │\n",
              "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
              "│    0.81% │\u001b[31m     3.6 ms │     4 │ 899.91 µs ± 408.36 (655.17 ‥ 1510.38) │\u001b[1m cuStreamSynchronize     │\n",
              "│    0.14% │\u001b[33m  642.06 µs │     4 │ 160.52 µs ± 80.21  ( 89.41 ‥ 242.23)  │\u001b[1m cuModuleLoadDataEx      │\n",
              "│    0.05% │  207.42 µs │    16 │  12.96 µs ± 11.96  (  4.29 ‥ 41.01)   │ cuLaunchKernel          │\n",
              "│    0.05% │  204.32 µs │     4 │  51.08 µs ± 9.64   ( 44.11 ‥ 65.33)   │ cuModuleGetFunction     │\n",
              "│    0.02% │   109.2 µs │     8 │  13.65 µs ± 8.01   (  3.81 ‥ 25.03)   │ cuMemAllocFromPoolAsync │\n",
              "│    0.02% │  103.24 µs │     4 │  25.81 µs ± 6.82   (  21.7 ‥ 36.0)    │ cudaLaunchKernel        │\n",
              "│    0.01% │   56.51 µs │     4 │  14.13 µs ± 0.66   ( 13.35 ‥ 14.78)   │ cuCtxSynchronize        │\n",
              "│    0.00% │    7.39 µs │     8 │ 923.87 ns ± 965.84 (   0.0 ‥ 2384.19) │ cudaGetLastError        │\n",
              "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
              "\n",
              "Device-side activity: GPU was busy for 6.64 ms (1.49% of the trace)\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                              │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│    0.46% │\u001b[31m    2.06 ms │     4 │ 515.52 µs ± 2.22   (513.08 ‥ 517.85) │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) │\n",
              "│    0.29% │\u001b[33m    1.27 ms │     4 │ 318.65 µs ± 1.84   (316.14 ‥ 320.43) │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) │\n",
              "│    0.28% │    1.26 ms │     4 │  315.9 µs ± 0.85   (315.19 ‥ 317.1)  │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
              "│    0.28% │    1.25 ms │     4 │ 313.58 µs ± 1.3    (312.57 ‥ 315.43) │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
              "│    0.18% │  782.97 µs │     4 │ 195.74 µs ± 10.07  (183.82 ‥ 205.76) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                    │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
              "\n",
              "NVTX ranges:\n",
              "┌──────────┬────────────┬───────┬─────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                                        │\n",
              "├──────────┼────────────┼───────┼─────────────────────────────────────────────┤\n",
              "│   31.65% │\u001b[31m  140.86 ms │     1 │\u001b[1m Main.Localmem copy (32, 32) bank=false      │\n",
              "│   26.15% │  116.34 ms │     1 │ Main.Localmem transpose (32, 32) bank=false │\n",
              "│   25.52% │  113.54 ms │     1 │ Main.Localmem transpose (32, 32) bank=true  │\n",
              "│   16.65% │   74.11 ms │     1 │ Main.Localmem copy (32, 32) bank=true       │\n",
              "└──────────┴────────────┴───────┴─────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "# Benchmark localmem\n",
        "CUDA.@profile for (name, kernel) in (\n",
        "        (\"copy\", lmem_copy_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
        "        (\"transpose\", lmem_transpose_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
        "    )\n",
        "    for bank in (true, false)\n",
        "        NVTX.@range \"Localmem $name ($TILE_DIM, $TILE_DIM) bank=$bank\" let\n",
        "            input = rand!(allocate(backend, T, N, N))\n",
        "            output = similar(input)\n",
        "\n",
        "            # compile kernel\n",
        "            kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
        "            for rep in 1:nreps\n",
        "                kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
        "            end\n",
        "            KernelAbstractions.synchronize(backend)\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXxdCZBVVfj1",
        "outputId": "c39c1bf3-b0e4-4dee-ebae-527973b51722"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Profiler ran for 500.16 ms, capturing 3662 events.\n",
              "\n",
              "Host-side activity: calling CUDA APIs took 2.48 ms (0.50% of the trace)\n",
              "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                     │\u001b[1m Name                    │\n",
              "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
              "│    0.26% │\u001b[31m    1.31 ms │     4 │ 326.34 µs ± 534.42 (  7.63 ‥ 1122.71) │\u001b[1m cuStreamSynchronize     │\n",
              "│    0.19% │\u001b[33m  953.44 µs │     4 │ 238.36 µs ± 23.27  (215.05 ‥ 267.51)  │\u001b[1m cuModuleLoadDataEx      │\n",
              "│    0.04% │  212.67 µs │     4 │  53.17 µs ± 11.1   ( 45.06 ‥ 69.14)   │ cuModuleGetFunction     │\n",
              "│    0.04% │  183.11 µs │    16 │  11.44 µs ± 10.29  (  4.53 ‥ 30.04)   │ cuLaunchKernel          │\n",
              "│    0.02% │    96.8 µs │     4 │   24.2 µs ± 4.73   ( 20.27 ‥ 30.99)   │ cudaLaunchKernel        │\n",
              "│    0.02% │   91.79 µs │     8 │  11.47 µs ± 7.62   (  3.58 ‥ 21.22)   │ cuMemAllocFromPoolAsync │\n",
              "│    0.01% │   60.56 µs │     4 │  15.14 µs ± 1.41   ( 13.83 ‥ 16.69)   │ cuCtxSynchronize        │\n",
              "│    0.00% │   24.56 µs │     8 │   3.07 µs ± 6.61   (   0.0 ‥ 19.31)   │ cudaGetLastError        │\n",
              "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
              "\n",
              "Device-side activity: GPU was busy for 4.21 ms (0.84% of the trace)\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                                  │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│    0.33% │\u001b[31m    1.65 ms │     4 │ 413.18 µs ± 0.19   (412.94 ‥ 413.42) │\u001b[1m gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) │\n",
              "│    0.16% │\u001b[33m  780.11 µs │     4 │ 195.03 µs ± 7.47   (187.87 ‥ 201.94) │\u001b[1m void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                        │\n",
              "│    0.13% │   665.9 µs │     4 │ 166.48 µs ± 1.89   (164.27 ‥ 168.8)  │ gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) │\n",
              "│    0.11% │  556.23 µs │     4 │ 139.06 µs ± 0.86   (138.28 ‥ 140.19) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
              "│    0.11% │  553.61 µs │     4 │  138.4 µs ± 0.74   (137.81 ‥ 139.47) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
              "\n",
              "NVTX ranges:\n",
              "┌──────────┬────────────┬───────┬────────────────────────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Name                                                           │\n",
              "├──────────┼────────────┼───────┼────────────────────────────────────────────────────────────────┤\n",
              "│   25.36% │\u001b[31m  126.87 ms │     1 │\u001b[1m Main.Localmem + multiple elements transpose (32, 8) bank=false │\n",
              "│   25.07% │  125.39 ms │     1 │ Main.Localmem + multiple elements copy (32, 8) bank=true       │\n",
              "│   25.02% │  125.13 ms │     1 │ Main.Localmem + multiple elements transpose (32, 8) bank=true  │\n",
              "│   24.52% │  122.64 ms │     1 │ Main.Localmem + multiple elements copy (32, 8) bank=false      │\n",
              "└──────────┴────────────┴───────┴────────────────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# Benchmark localmem + multiple elements per lane\n",
        "CUDA.@profile for (name, kernel) in (\n",
        "        (\"copy\", coalesced_copy_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
        "        (\"transpose\", coalesced_transpose_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
        "    )\n",
        "    for bank in (true, false)\n",
        "        NVTX.@range \"Localmem + multiple elements $name ($TILE_DIM, $BLOCK_ROWS) bank=$bank\" let\n",
        "            input = rand!(allocate(backend, T, N, N))\n",
        "            output = similar(input)\n",
        "\n",
        "            # We want a number of blocks equivalent to (TILE_DIM, TILE_DIM)\n",
        "            # but our blocks are (TILE_DIM, BLOCK_ROWS) so we need to remove\n",
        "            # a factor from the size of the array otherwise we get to many blocks\n",
        "            block_factor = div(TILE_DIM, BLOCK_ROWS)\n",
        "            ndrange = (N, div(N, block_factor))\n",
        "\n",
        "            # compile kernel\n",
        "            kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
        "            for rep in 1:nreps\n",
        "                kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
        "            end\n",
        "            KernelAbstractions.synchronize(backend)\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoCwrdAKd1Ut"
      },
      "source": [
        "## Matrix multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "jJ7ErQTfd4ZO"
      },
      "outputs": [],
      "source": [
        "@kernel function naive_matmul_kernel!(output, a, b)\n",
        "    i, j = @index(Global, NTuple)\n",
        "\n",
        "    # creating a temporary sum variable for matrix multiplication\n",
        "    tmp_sum = zero(eltype(output))\n",
        "    for k in 1:size(a)[2]\n",
        "        tmp_sum += a[i, k] * b[k, j]\n",
        "    end\n",
        "\n",
        "    output[i, j] = tmp_sum\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "-miQrox1ebjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74eea227-2c10-4f59-ebc3-773bf9744281"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "naive_matmul! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "# Creating a wrapper kernel for launching with error checks\n",
        "function naive_matmul!(output, a, b)\n",
        "    if size(a)[2] != size(b)[1]\n",
        "        println(\"Matrix size mismatch!\")\n",
        "        return nothing\n",
        "    end\n",
        "    backend = KernelAbstractions.get_backend(a)\n",
        "    kernel! = naive_matmul_kernel!(backend)\n",
        "    kernel!(output, a, b, ndrange = size(output))\n",
        "    return\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "fc4MplI9d89w"
      },
      "outputs": [],
      "source": [
        "let\n",
        "  a = rand!(allocate(backend, Float32, 256, 123))\n",
        "  b = rand!(allocate(backend, Float32, 123, 45))\n",
        "  output = KernelAbstractions.zeros(backend, Float32, 256, 45)\n",
        "\n",
        "  naive_matmul!(output, a, b)\n",
        "\n",
        "  @assert isapprox(output, a * b)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "mN1LbGM7eGZL"
      },
      "outputs": [],
      "source": [
        "@kernel unsafe_indices = true function coalesced_matmul_kernel!(\n",
        "        output, @Const(A), @Const(B),\n",
        "        ::Val{BANK} = Val(1),\n",
        "    ) where {BANK}\n",
        "    gi, gj = @index(Group, NTuple)\n",
        "    i, j = @index(Local, NTuple)\n",
        "\n",
        "    TILE_DIM = @uniform @groupsize()[1]\n",
        "\n",
        "    # +1 to avoid bank conflicts on shared memory\n",
        "    tile1 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
        "    tile2 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
        "\n",
        "    # private variable for tile output\n",
        "    outval = @private eltype(output) 1\n",
        "    @inbounds outval[1] = -zero(eltype(output))\n",
        "\n",
        "    @uniform N = size(output, 1)\n",
        "    @uniform M = size(output, 2)\n",
        "    @uniform R = size(A, 2)\n",
        "    # number of tiles depends on inner dimension\n",
        "    @uniform NUM_TILES = div(R + TILE_DIM - 1, TILE_DIM)\n",
        "\n",
        "    # loop over all tiles needed for this calculation\n",
        "    for t in 0:(NUM_TILES - 1)\n",
        "        # Can't use @index(Global), because we use a smaller ndrange\n",
        "        I = (gi - 1) * TILE_DIM + i\n",
        "        J = (gj - 1) * TILE_DIM + j\n",
        "\n",
        "        # load inputs into tiles, with bounds checking for non-square matrices\n",
        "        if I <= N && t * TILE_DIM + j <= R\n",
        "            @inbounds tile1[i, j] = A[I, t * TILE_DIM + j]\n",
        "        else\n",
        "            @inbounds tile1[i, j] = 0.0\n",
        "        end\n",
        "        if t * TILE_DIM + i <= R && J <= M\n",
        "            @inbounds tile2[i, j] = B[t * TILE_DIM + i, J]\n",
        "        else\n",
        "            @inbounds tile2[i, j] = 0.0\n",
        "        end\n",
        "\n",
        "        # wait for all tiles to be loaded\n",
        "        @synchronize\n",
        "\n",
        "        # get global values again\n",
        "        I = (gi - 1) * TILE_DIM + i\n",
        "        J = (gj - 1) * TILE_DIM + j\n",
        "\n",
        "        # calculate value of spot in output, use temporary value to allow for vectorization\n",
        "        out = zero(eltype(output))\n",
        "        @simd for k in 1:TILE_DIM\n",
        "            @inbounds out += tile1[i, k] * tile2[k, j]\n",
        "        end\n",
        "        outval[1] += out\n",
        "\n",
        "        @synchronize\n",
        "    end\n",
        "\n",
        "    # get global indices again\n",
        "    I = (gi - 1) * TILE_DIM + i\n",
        "    J = (gj - 1) * TILE_DIM + j\n",
        "\n",
        "    # save if inbounds\n",
        "    if I <= N && J <= M\n",
        "        @inbounds output[I, J] = outval[1]\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE4LNL5Zecj3",
        "outputId": "7b2e0470-cdf9-41cd-d931-24501d7d8277"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "coalesced_matmul! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# Creating a wrapper kernel for launching with error checks\n",
        "function coalesced_matmul!(output, a, b)\n",
        "    if size(a)[2] != size(b)[1]\n",
        "        println(\"Matrix size mismatch!\")\n",
        "        return nothing\n",
        "    end\n",
        "    backend = KernelAbstractions.get_backend(a)\n",
        "    kernel! = coalesced_matmul_kernel!(backend, (TILE_DIM, TILE_DIM))\n",
        "    kernel!(output, a, b, ndrange = size(output))\n",
        "    return\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "jM9J-KMnetKN"
      },
      "outputs": [],
      "source": [
        "let\n",
        "  a = rand!(allocate(backend, Float32, 256, 123))\n",
        "  b = rand!(allocate(backend, Float32, 123, 45))\n",
        "  output = KernelAbstractions.zeros(backend, Float32, 256, 45)\n",
        "\n",
        "  coalesced_matmul!(output, a, b)\n",
        "\n",
        "  @assert isapprox(output, a * b)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "i3ZPZNcmfv3b"
      },
      "outputs": [],
      "source": [
        "import LinearAlgebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw9Uuzn0hM0I"
      },
      "source": [
        "### Exercise\n",
        "- Vary N, R, M\n",
        "- Vary T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOwz86oLfYjs",
        "outputId": "8a69d2a3-41df-42b2-8352-4153e2005ea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Profiler ran for 508.6 ms, capturing 7434 events.\n",
              "\n",
              "Host-side activity: calling CUDA APIs took 69.49 ms (13.66% of the trace)\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                    │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────┤\n",
              "│   40.07% │\u001b[31m  203.78 ms │     9 │  22.64 ms ± 3.22   ( 18.84 ‥ 26.68)  │\u001b[1m cuStreamSynchronize     │\n",
              "│    0.09% │\u001b[33m  446.32 µs │     2 │ 223.16 µs ± 14.84  (212.67 ‥ 233.65) │\u001b[1m cuModuleLoadDataEx      │\n",
              "│    0.03% │\u001b[33m  170.23 µs │     6 │  28.37 µs ± 2.71   (  24.8 ‥ 31.95)  │\u001b[1m cuLaunchKernel          │\n",
              "│    0.02% │  119.69 µs │     2 │  59.84 µs ± 13.15  ( 50.54 ‥ 69.14)  │ cuModuleGetFunction     │\n",
              "│    0.02% │   89.88 µs │     6 │  14.98 µs ± 9.43   (  4.77 ‥ 24.32)  │ cuMemAllocFromPoolAsync │\n",
              "│    0.02% │   86.07 µs │     6 │  14.34 µs ± 14.0   (  3.58 ‥ 40.29)  │ cuMemcpyHtoDAsync       │\n",
              "│    0.01% │    63.9 µs │     3 │   21.3 µs ± 3.65   ( 19.07 ‥ 25.51)  │ cudaLaunchKernel        │\n",
              "│    0.00% │   24.08 µs │     2 │  12.04 µs ± 0.51   ( 11.68 ‥ 12.4)   │ cuCtxSynchronize        │\n",
              "│    0.00% │    2.15 µs │     3 │ 715.26 ns ± 0.0    (715.26 ‥ 715.26) │ cudaGetLastError        │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────┘\n",
              "\n",
              "Device-side activity: GPU was busy for 207.76 ms (40.85% of the trace)\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                                                                                                                                                                                                                                                                                                                                                                                │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│   14.76% │\u001b[31m   75.06 ms │     3 │  25.02 ms ± 3.62   ( 20.84 ‥ 27.12)  │\u001b[1m gpu_coalesced_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float64, 2, 1>, Float64, Float64)                                                                                │\n",
              "│   13.44% │   68.34 ms │     3 │  22.78 ms ± 2.88   ( 19.45 ‥ 24.45)  │ gpu_naive_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, DynamicSize, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>>>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>) │\n",
              "│   12.65% │   64.35 ms │     3 │  21.45 ms ± 3.28   ( 19.27 ‥ 25.22)  │ volta_dgemm_128x64_nn                                                                                                                                                                                                                                                                                                                                                               │\n",
              "│    0.00% │    4.53 µs │     6 │ 754.99 ns ± 179.47 (476.84 ‥ 953.67) │ [copy pageable to device memory]                                                                                                                                                                                                                                                                                                                                                    │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
              "\n",
              "NVTX ranges:\n",
              "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────┐\n",
              "│\u001b[1m Time (%) │\u001b[1m Total time │\u001b[1m Calls │\u001b[1m Time distribution                    │\u001b[1m Name                    │\n",
              "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────┤\n",
              "│   47.27% │\u001b[31m  240.44 ms │     3 │  80.15 ms ± 97.07  ( 20.99 ‥ 192.17) │\u001b[1m Main.Coalesced Matmul   │\n",
              "│   39.90% │  202.91 ms │     3 │  67.64 ms ± 78.9   (  19.6 ‥ 158.7)  │ Main.Naive Matmul       │\n",
              "│   12.82% │   65.21 ms │     3 │  21.74 ms ± 3.33   ( 19.53 ‥ 25.56)  │ Main.LinearAlgebra.mul! │\n",
              "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "let\n",
        "    N = 1024\n",
        "    R = 512\n",
        "    M = 2048\n",
        "    T = Float64\n",
        "    A = rand!(allocate(backend, T, N, R))\n",
        "    B = rand!(allocate(backend, T, R, M))\n",
        "    output_naive = KernelAbstractions.zeros(backend, T, N, M)\n",
        "    output_coalesced = KernelAbstractions.zeros(backend, T, N, M)\n",
        "    output_mul = KernelAbstractions.zeros(backend, T, N, M)\n",
        "\n",
        "\n",
        "    CUDA.@profile for _ in 1:nreps\n",
        "      NVTX.@range \"Naive Matmul\" begin\n",
        "          naive_matmul!(output_naive, A, B)\n",
        "          KernelAbstractions.synchronize(backend)\n",
        "      end\n",
        "\n",
        "      NVTX.@range \"Coalesced Matmul\" begin\n",
        "          coalesced_matmul!(output_coalesced, A, B)\n",
        "          KernelAbstractions.synchronize(backend)\n",
        "      end\n",
        "\n",
        "      NVTX.@range \"LinearAlgebra.mul!\" begin\n",
        "          LinearAlgebra.mul!(output_mul, A, B)\n",
        "          KernelAbstractions.synchronize(backend)\n",
        "      end\n",
        "    end\n",
        "end"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}